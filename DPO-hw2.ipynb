{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"e927f642223a4091b7f6e6e979fd0dd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a569fa1aee484c08977b587ba6888ca0","IPY_MODEL_9df118328b674ba4ae3fa8133198ff1f","IPY_MODEL_73a0cb0ccce743eb888293886881c868"],"layout":"IPY_MODEL_5b6b4105754c493593f5ebfac9ea8ebd"}},"a569fa1aee484c08977b587ba6888ca0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0da9fe5759ea4d32a0c0ccae3fddb963","placeholder":"​","style":"IPY_MODEL_bf43c10f41a44fc3b668d4f780421803","value":"README.md: 100%"}},"9df118328b674ba4ae3fa8133198ff1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3e4d72b5e74a27ace1f9b78df28cba","max":6529,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0aced4056a184440b70fc7e17cc141b4","value":6529}},"73a0cb0ccce743eb888293886881c868":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d069d84c4a0d4d62b2cc61b9f24a4dcc","placeholder":"​","style":"IPY_MODEL_2ba534563e1f4059898ec07736543ef7","value":" 6.53k/6.53k [00:00&lt;00:00, 231kB/s]"}},"5b6b4105754c493593f5ebfac9ea8ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0da9fe5759ea4d32a0c0ccae3fddb963":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf43c10f41a44fc3b668d4f780421803":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd3e4d72b5e74a27ace1f9b78df28cba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aced4056a184440b70fc7e17cc141b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d069d84c4a0d4d62b2cc61b9f24a4dcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ba534563e1f4059898ec07736543ef7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bebf518f300f44248d8fe0b6fb605dee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a4d2507d2684c63b3fa1feaae4d3ced","IPY_MODEL_e8ff6ac7344a48f68c7f9091bd3c053c","IPY_MODEL_547b77c3a7044ec698f2a8b750d0965d"],"layout":"IPY_MODEL_73062d4e94634775b038bdc8bc9f668b"}},"7a4d2507d2684c63b3fa1feaae4d3ced":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e248db4153f2441199473e2af678c763","placeholder":"​","style":"IPY_MODEL_08e1bee342dc4cfe98c90a900aaf0256","value":"train_prefs-00000-of-00001.parquet: 100%"}},"e8ff6ac7344a48f68c7f9091bd3c053c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad17996822f14317ac95672116a06c3f","max":225891836,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe2b2d25480f4705b9ab373632c5183d","value":225891836}},"547b77c3a7044ec698f2a8b750d0965d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35d7e337fedc46c0ad7c66bba25766d0","placeholder":"​","style":"IPY_MODEL_050e3582eb764044b2635cb8d2ae5f6b","value":" 226M/226M [00:01&lt;00:00, 154MB/s]"}},"73062d4e94634775b038bdc8bc9f668b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e248db4153f2441199473e2af678c763":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08e1bee342dc4cfe98c90a900aaf0256":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad17996822f14317ac95672116a06c3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe2b2d25480f4705b9ab373632c5183d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35d7e337fedc46c0ad7c66bba25766d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"050e3582eb764044b2635cb8d2ae5f6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7ebdef324154a81871bdecc9f401016":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f11486e9b76d4e0685fe93c41a753c2b","IPY_MODEL_e4c77dbaddd24419829698c1de1d414a","IPY_MODEL_453748ff336d4d6fac4fd700755e4479"],"layout":"IPY_MODEL_67106ad799cc4580a7616f1780677143"}},"f11486e9b76d4e0685fe93c41a753c2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9549bd687a9a4db2a9f8cc21e74e380a","placeholder":"​","style":"IPY_MODEL_8d822f2d4c694addb95a995ab4a10283","value":"test_prefs-00000-of-00001.parquet: 100%"}},"e4c77dbaddd24419829698c1de1d414a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5df2b31dfddf43eb85785e72fec95955","max":7291160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e755ce1ffda4628a09d5830a1f76969","value":7291160}},"453748ff336d4d6fac4fd700755e4479":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7e8194204aa4f6f9944e93014bb275c","placeholder":"​","style":"IPY_MODEL_cd370760f38d4ccfb9ea4ee495c91de0","value":" 7.29M/7.29M [00:00&lt;00:00, 48.5MB/s]"}},"67106ad799cc4580a7616f1780677143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9549bd687a9a4db2a9f8cc21e74e380a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d822f2d4c694addb95a995ab4a10283":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5df2b31dfddf43eb85785e72fec95955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e755ce1ffda4628a09d5830a1f76969":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7e8194204aa4f6f9944e93014bb275c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd370760f38d4ccfb9ea4ee495c91de0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b1e2b8ed951472b9e107d846f7eeba6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_914b581b0264419ca86c496c70e1bad1","IPY_MODEL_8fb4d1c158454bd581453e1f7417b584","IPY_MODEL_16f30199b93c4924baa566833e3bac3f"],"layout":"IPY_MODEL_287ddf54c75e4f08a7a9f062eac256b7"}},"914b581b0264419ca86c496c70e1bad1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24c1a81f62dc4ea9b7cf60313658dce3","placeholder":"​","style":"IPY_MODEL_bd488aca96654e0da4bf2913411c1ddd","value":"test_sft-00000-of-00001.parquet: 100%"}},"8fb4d1c158454bd581453e1f7417b584":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_64423133632d4912b0e32d137e416d06","max":3719085,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d01132e9590940938a4f55933d541370","value":3719085}},"16f30199b93c4924baa566833e3bac3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef27e1517b074753921d45a9a037c1e9","placeholder":"​","style":"IPY_MODEL_eab872731fb446ecb5fcdbdf4165b44e","value":" 3.72M/3.72M [00:00&lt;00:00, 64.0MB/s]"}},"287ddf54c75e4f08a7a9f062eac256b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24c1a81f62dc4ea9b7cf60313658dce3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd488aca96654e0da4bf2913411c1ddd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64423133632d4912b0e32d137e416d06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d01132e9590940938a4f55933d541370":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef27e1517b074753921d45a9a037c1e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eab872731fb446ecb5fcdbdf4165b44e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95dbb7a1097e453385866c1ed78f404c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f32d2624c382447c9488c8aa7076fea2","IPY_MODEL_682b2dfd019a45f195e259f749d1beb0","IPY_MODEL_87af11d01c7a46eabd4b429d2fce36db"],"layout":"IPY_MODEL_0609d3911d2740d8bde03aadec88a070"}},"f32d2624c382447c9488c8aa7076fea2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_418b074d096d4f2da523e0926828950d","placeholder":"​","style":"IPY_MODEL_7ac32880e0bd495daeec72f492047e39","value":"train_gen-00000-of-00001.parquet: 100%"}},"682b2dfd019a45f195e259f749d1beb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1df06b3d63e44b168ebb7a1677a1c869","max":184150527,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d5de84a102345c4b04fecad9ed3bf43","value":184150527}},"87af11d01c7a46eabd4b429d2fce36db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e28591037f8b41229536f0b257c0727b","placeholder":"​","style":"IPY_MODEL_31964ae9f7a24392ad8c02ea31ed3c8f","value":" 184M/184M [00:01&lt;00:00, 122MB/s]"}},"0609d3911d2740d8bde03aadec88a070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"418b074d096d4f2da523e0926828950d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ac32880e0bd495daeec72f492047e39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1df06b3d63e44b168ebb7a1677a1c869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d5de84a102345c4b04fecad9ed3bf43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e28591037f8b41229536f0b257c0727b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31964ae9f7a24392ad8c02ea31ed3c8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52af5e945cbc41bfb9b88bc311c2f7b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_145e927ffc0140c29ef66d6b1e8d9878","IPY_MODEL_9685a6e3c133402aa476ade0c3848314","IPY_MODEL_eedc9337623d4fd294e9857620759118"],"layout":"IPY_MODEL_bb940b71e76749fb90b87a2c03b0b011"}},"145e927ffc0140c29ef66d6b1e8d9878":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_998b7e5238284bc8991a0f7d5d8454a5","placeholder":"​","style":"IPY_MODEL_dc38e7312ff649b3baddd5b4c9baad6e","value":"test_gen-00000-of-00001.parquet: 100%"}},"9685a6e3c133402aa476ade0c3848314":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6218019794f4087963087cbe647e711","max":3022752,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be3b8e1f0d3a483589036956e88fe819","value":3022752}},"eedc9337623d4fd294e9857620759118":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dde6c4ed1f544596b6db308b9b2438e0","placeholder":"​","style":"IPY_MODEL_ba817e93385e474cb30ec30d443a1f46","value":" 3.02M/3.02M [00:00&lt;00:00, 80.1MB/s]"}},"bb940b71e76749fb90b87a2c03b0b011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998b7e5238284bc8991a0f7d5d8454a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc38e7312ff649b3baddd5b4c9baad6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6218019794f4087963087cbe647e711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be3b8e1f0d3a483589036956e88fe819":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dde6c4ed1f544596b6db308b9b2438e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba817e93385e474cb30ec30d443a1f46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01024fe41e8045a19cce88a86ae5ee7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebb0fff3259a4345b7bb8f05552c09b7","IPY_MODEL_8330dc00da4844cc85eb030ae54dcdc3","IPY_MODEL_afcafa0a748e40c4a06d87771c42ab69"],"layout":"IPY_MODEL_81fa489fca5942ef931cfde0e03e7a28"}},"ebb0fff3259a4345b7bb8f05552c09b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c5ba2eae91a4dca8d888a25e1049edc","placeholder":"​","style":"IPY_MODEL_20ccd2c5b78b4f2abb1fc22690029554","value":"Generating train_prefs split: 100%"}},"8330dc00da4844cc85eb030ae54dcdc3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bc81ba58e0b493da4828bf6fbd4d3d8","max":61135,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eaae8772ef324b5a93073615ad9fa28f","value":61135}},"afcafa0a748e40c4a06d87771c42ab69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9ff1b2d565b493a84095cbd056daa9e","placeholder":"​","style":"IPY_MODEL_5df6da418ec745a78305ee1ee9ebe4e6","value":" 61135/61135 [00:04&lt;00:00, 14028.49 examples/s]"}},"81fa489fca5942ef931cfde0e03e7a28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c5ba2eae91a4dca8d888a25e1049edc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20ccd2c5b78b4f2abb1fc22690029554":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bc81ba58e0b493da4828bf6fbd4d3d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaae8772ef324b5a93073615ad9fa28f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9ff1b2d565b493a84095cbd056daa9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5df6da418ec745a78305ee1ee9ebe4e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58824426d96e4a48bdefce96226fad55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_956feae422434e0fa18610cda32122b9","IPY_MODEL_8a95337d958f4566898663a5524f0796","IPY_MODEL_f0a1361cc93a4635b5382baa2fac40f1"],"layout":"IPY_MODEL_83d1ec0ad29648619723e415fbb846e6"}},"956feae422434e0fa18610cda32122b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c44e8ab485044969afb75ae6e7aa7329","placeholder":"​","style":"IPY_MODEL_7cfcf73bdcea4490b9696b3dd83373ff","value":"Generating train_sft split: 100%"}},"8a95337d958f4566898663a5524f0796":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4f6e3dea1ee41228c3339df265c8fb3","max":61135,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31d384f8bbf14c60a90d72517dfdd6be","value":61135}},"f0a1361cc93a4635b5382baa2fac40f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df3c3ef86fab4dbaba278f14cc3de605","placeholder":"​","style":"IPY_MODEL_3bbf29122a2548cf96a269e1376b3cb3","value":" 61135/61135 [00:05&lt;00:00, 15156.13 examples/s]"}},"83d1ec0ad29648619723e415fbb846e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c44e8ab485044969afb75ae6e7aa7329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cfcf73bdcea4490b9696b3dd83373ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4f6e3dea1ee41228c3339df265c8fb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d384f8bbf14c60a90d72517dfdd6be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df3c3ef86fab4dbaba278f14cc3de605":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bbf29122a2548cf96a269e1376b3cb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e7f2cc702324d899ce4c40c7bc60a1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7dda8e620414d839492139a806685f8","IPY_MODEL_faac089ac7004c9a8044a9d19fbe8b7e","IPY_MODEL_9114e2f2068c4feea30f331f488264c8"],"layout":"IPY_MODEL_09b947d1a1f043ab82cc6c5c444b9e18"}},"d7dda8e620414d839492139a806685f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b1a7c850df41adbc434041c19a7d28","placeholder":"​","style":"IPY_MODEL_0778459f77354d419bf35db506037260","value":"Generating test_prefs split: 100%"}},"faac089ac7004c9a8044a9d19fbe8b7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_659d4ccdd3ad4fd3b613fc536085edfa","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_922b1a74e35144a1b527bd0d3da9339c","value":2000}},"9114e2f2068c4feea30f331f488264c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_197a5429406c4f2eaf21d4b73b8d60c9","placeholder":"​","style":"IPY_MODEL_7f68b1e149e64577b8a4232d9fcc62e8","value":" 2000/2000 [00:00&lt;00:00, 3356.15 examples/s]"}},"09b947d1a1f043ab82cc6c5c444b9e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b1a7c850df41adbc434041c19a7d28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0778459f77354d419bf35db506037260":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"659d4ccdd3ad4fd3b613fc536085edfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"922b1a74e35144a1b527bd0d3da9339c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"197a5429406c4f2eaf21d4b73b8d60c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f68b1e149e64577b8a4232d9fcc62e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"177f8323cdbe489dae691c8570cb1bc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee518d886b6d44a0afe500febb7d6ae5","IPY_MODEL_e4ef8b9c49264ca582e14b2d8291df0e","IPY_MODEL_e3d9a93fb0d64b968961842cf7e659ab"],"layout":"IPY_MODEL_eb5d5314ed034b6389c0d87363d27c48"}},"ee518d886b6d44a0afe500febb7d6ae5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc73e60b36df464fb4250ddc6eb5029f","placeholder":"​","style":"IPY_MODEL_d57d0945653b41b3a5e3c2a514f463bf","value":"Generating test_sft split: 100%"}},"e4ef8b9c49264ca582e14b2d8291df0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6326552b6ea04a5794bb39c6b2c7d6b0","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bfa350cd7e47404bb1190171182068b9","value":1000}},"e3d9a93fb0d64b968961842cf7e659ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0226a44084d4f33802c24d22a2b5cf3","placeholder":"​","style":"IPY_MODEL_b9e1dc5044c74c28ab841cad2f477124","value":" 1000/1000 [00:00&lt;00:00, 7275.71 examples/s]"}},"eb5d5314ed034b6389c0d87363d27c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc73e60b36df464fb4250ddc6eb5029f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d57d0945653b41b3a5e3c2a514f463bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6326552b6ea04a5794bb39c6b2c7d6b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfa350cd7e47404bb1190171182068b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0226a44084d4f33802c24d22a2b5cf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e1dc5044c74c28ab841cad2f477124":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89b7298d3cb542b7ae9686d15b8cdfd1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a833fec7cc5e439a96b961a21fa96981","IPY_MODEL_8e6f2c7d447a407e8a6f37eee22203c9","IPY_MODEL_f301a697d5e64ac7aee03acbe94b2684"],"layout":"IPY_MODEL_cee98ee1c7b5401d9ff6ba93bffc444f"}},"a833fec7cc5e439a96b961a21fa96981":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_878a8b06dc244c2596ff3f31c6045e3c","placeholder":"​","style":"IPY_MODEL_4e15c064c0b24e219c09a3d2dbbb239c","value":"Generating train_gen split: 100%"}},"8e6f2c7d447a407e8a6f37eee22203c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d11b48b63c12496b9931b496479532a1","max":61135,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c22ae20175f54c0baed28935af89f658","value":61135}},"f301a697d5e64ac7aee03acbe94b2684":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0be0cb2b309c41aca96f62a49cd3c400","placeholder":"​","style":"IPY_MODEL_9a83ecf2e2994828bf4b6c6298817fd8","value":" 61135/61135 [00:03&lt;00:00, 18631.03 examples/s]"}},"cee98ee1c7b5401d9ff6ba93bffc444f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"878a8b06dc244c2596ff3f31c6045e3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e15c064c0b24e219c09a3d2dbbb239c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d11b48b63c12496b9931b496479532a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c22ae20175f54c0baed28935af89f658":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0be0cb2b309c41aca96f62a49cd3c400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a83ecf2e2994828bf4b6c6298817fd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05920b40c18b4cdc93fd19daf6e7b3e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3abee125688b4764ad865370658bc509","IPY_MODEL_3d6a67adf1a240aea631109d548bb170","IPY_MODEL_401a91dba2854e698d13e607b8ff8955"],"layout":"IPY_MODEL_21b1ca87613d4a7882a6ba604884c57d"}},"3abee125688b4764ad865370658bc509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f87713d1927459dac5cbdf7d328ccae","placeholder":"​","style":"IPY_MODEL_f2de6bee8d8043c7b8759ab4828efc10","value":"Generating test_gen split: 100%"}},"3d6a67adf1a240aea631109d548bb170":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_169432aebbf64fca82c4c29bbcdc6735","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8af38abb76a4bde9310961b017cb4ea","value":1000}},"401a91dba2854e698d13e607b8ff8955":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea5df22658e64b65bef512f63671a371","placeholder":"​","style":"IPY_MODEL_0a57898d58ed4aca913e0939744e257f","value":" 1000/1000 [00:00&lt;00:00, 8659.24 examples/s]"}},"21b1ca87613d4a7882a6ba604884c57d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f87713d1927459dac5cbdf7d328ccae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2de6bee8d8043c7b8759ab4828efc10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"169432aebbf64fca82c4c29bbcdc6735":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8af38abb76a4bde9310961b017cb4ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea5df22658e64b65bef512f63671a371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a57898d58ed4aca913e0939744e257f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51fc2ff8a5964b8eaee6f573b7481d4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_461ead21de994b7baad39a385d8a6ff6","IPY_MODEL_87ed781c75ed42f98b44b12d212777c6","IPY_MODEL_3424b68cf5604acbaa496d12d9a5425c"],"layout":"IPY_MODEL_ff0960181919410b89ade334ae1eef16"}},"461ead21de994b7baad39a385d8a6ff6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9d0c2ee1f9d44ff8a0512482497b6d3","placeholder":"​","style":"IPY_MODEL_329cea7a3c7142f39d2480ecabb4b48e","value":"Filter: 100%"}},"87ed781c75ed42f98b44b12d212777c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5c194288a194b0a91fc32cbf0a5ac6f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df8ff18c36854bfd8ac1ff8730457715","value":2}},"3424b68cf5604acbaa496d12d9a5425c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3df98b4335a44ee58c42dd8e007b12e0","placeholder":"​","style":"IPY_MODEL_f587e3df16ef4dcdb3334cff6d42ffa9","value":" 2/2 [00:03&lt;00:00,  1.79s/ examples]"}},"ff0960181919410b89ade334ae1eef16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d0c2ee1f9d44ff8a0512482497b6d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329cea7a3c7142f39d2480ecabb4b48e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5c194288a194b0a91fc32cbf0a5ac6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8ff18c36854bfd8ac1ff8730457715":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3df98b4335a44ee58c42dd8e007b12e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f587e3df16ef4dcdb3334cff6d42ffa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daa6ed54616e4954bb5c0f3414dd2283":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ed01baf07bf48cda752d37e2931ede6","IPY_MODEL_c042ae5fa9034ccd89b79aa9cfe2ab36","IPY_MODEL_76effb0e0ae949a08d377c9303f00c19"],"layout":"IPY_MODEL_de4880b8d4d140f990bd8006c64884f0"}},"3ed01baf07bf48cda752d37e2931ede6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd8d61beeb794779a84ff7a0e4add47f","placeholder":"​","style":"IPY_MODEL_80b59d4d4c98492ba6f3bd32c71fa9c8","value":"tokenizer_config.json: 100%"}},"c042ae5fa9034ccd89b79aa9cfe2ab36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3402e790a84f4136881cd9dd42d7f36f","max":3590,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8838687703fb49cba466c304dec458b3","value":3590}},"76effb0e0ae949a08d377c9303f00c19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9272a2a1ba3e43c58b366a21ac77f3d9","placeholder":"​","style":"IPY_MODEL_04710cdf4f3b4800aa22689a459a3e1d","value":" 3.59k/3.59k [00:00&lt;00:00, 65.7kB/s]"}},"de4880b8d4d140f990bd8006c64884f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd8d61beeb794779a84ff7a0e4add47f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b59d4d4c98492ba6f3bd32c71fa9c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3402e790a84f4136881cd9dd42d7f36f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8838687703fb49cba466c304dec458b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9272a2a1ba3e43c58b366a21ac77f3d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04710cdf4f3b4800aa22689a459a3e1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"603da3e19b6c4661a4de8439514d5d7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74096d154b974ef2b98d11bc36e41581","IPY_MODEL_dd353a3488fd4a70b39ced2117d4a5cb","IPY_MODEL_b2a5f586772f47b1ac26c4248da9b398"],"layout":"IPY_MODEL_566e57441f6746df9ab2a69ea122942c"}},"74096d154b974ef2b98d11bc36e41581":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_382dca2369ae49f09196ea2523f57b75","placeholder":"​","style":"IPY_MODEL_df36fdfb35ea4820a888f936a7d6637c","value":"vocab.json: 100%"}},"dd353a3488fd4a70b39ced2117d4a5cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fb6f916bcfe42f5b3a5aa58a60b56a6","max":800662,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79aee0db4bb24a90bce23ee2e5905a62","value":800662}},"b2a5f586772f47b1ac26c4248da9b398":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a5127824ff4d40b78e4003a7fbe750","placeholder":"​","style":"IPY_MODEL_60567efe431144bf89e736b6e799cd3f","value":" 801k/801k [00:00&lt;00:00, 3.33MB/s]"}},"566e57441f6746df9ab2a69ea122942c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"382dca2369ae49f09196ea2523f57b75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df36fdfb35ea4820a888f936a7d6637c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fb6f916bcfe42f5b3a5aa58a60b56a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79aee0db4bb24a90bce23ee2e5905a62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76a5127824ff4d40b78e4003a7fbe750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60567efe431144bf89e736b6e799cd3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d046f2a89ce04e508ce79ff2f92663dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5f7ac4e0acf4ca18c078d50af6952c4","IPY_MODEL_8f42df5acaf345648261345fbce5903d","IPY_MODEL_be23a41378f4450e8bc749445f6bfc6a"],"layout":"IPY_MODEL_c73c2b0754124455bd476003b2181883"}},"d5f7ac4e0acf4ca18c078d50af6952c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46b2afc5429d4e69876618f5aae79aa6","placeholder":"​","style":"IPY_MODEL_f7ac6ddd0682402fac9d7c79aa078588","value":"merges.txt: 100%"}},"8f42df5acaf345648261345fbce5903d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_349f0d30736d489c9b826feda69d3522","max":466391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8b23c322f95448281edfcf6c872d866","value":466391}},"be23a41378f4450e8bc749445f6bfc6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17cc436828e0443d835c67545c3ff38a","placeholder":"​","style":"IPY_MODEL_f71ad3a0e2c94e6aa50915deecb2003b","value":" 466k/466k [00:00&lt;00:00, 2.81MB/s]"}},"c73c2b0754124455bd476003b2181883":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b2afc5429d4e69876618f5aae79aa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ac6ddd0682402fac9d7c79aa078588":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"349f0d30736d489c9b826feda69d3522":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8b23c322f95448281edfcf6c872d866":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17cc436828e0443d835c67545c3ff38a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f71ad3a0e2c94e6aa50915deecb2003b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb0fabdfd5614d668101c2b59ba5b8df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bb2e8d34c044458b61055a737248548","IPY_MODEL_a2f0dfaf572b4656be8ca835cc123513","IPY_MODEL_334b6de2aa134d029bb99fc57c2d48b2"],"layout":"IPY_MODEL_d2f39459e8ef4239a419ec84bec0028e"}},"2bb2e8d34c044458b61055a737248548":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0531e5b5a2f4c3f935a09cfa8659a08","placeholder":"​","style":"IPY_MODEL_3f0681bf10b04c95b6fe5422cadfe6a2","value":"tokenizer.json: 100%"}},"a2f0dfaf572b4656be8ca835cc123513":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd5d26b821694128a123857b51d16665","max":2104556,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe613f4b736c4fbdaa26257e7c9bc398","value":2104556}},"334b6de2aa134d029bb99fc57c2d48b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36e19da0df9944a2a4395fa39a842782","placeholder":"​","style":"IPY_MODEL_ac7772aa53374ed1b74487b13e9e72fe","value":" 2.10M/2.10M [00:00&lt;00:00, 6.23MB/s]"}},"d2f39459e8ef4239a419ec84bec0028e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0531e5b5a2f4c3f935a09cfa8659a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f0681bf10b04c95b6fe5422cadfe6a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd5d26b821694128a123857b51d16665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe613f4b736c4fbdaa26257e7c9bc398":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36e19da0df9944a2a4395fa39a842782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac7772aa53374ed1b74487b13e9e72fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c994b4d52b334841a432d2aaa7550603":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8030eaa04e024ecbb896054e18aae7c0","IPY_MODEL_0712c4fbfb0c467cadbc8d564ded637d","IPY_MODEL_2da01bb85de94e21ad18e2ce82db0019"],"layout":"IPY_MODEL_00749d237a254028ac88de757f831454"}},"8030eaa04e024ecbb896054e18aae7c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67dddc30cbb74b01972ab58f7567f2e7","placeholder":"​","style":"IPY_MODEL_c16bd7467e794b7faba6033a0ad86fd2","value":"special_tokens_map.json: 100%"}},"0712c4fbfb0c467cadbc8d564ded637d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1beaedef8c464ea0f178311e9e6a5f","max":565,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9af28a95fe2444ad851e9239910c61f8","value":565}},"2da01bb85de94e21ad18e2ce82db0019":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ee8559284344ff487a0a9724b2ba4d5","placeholder":"​","style":"IPY_MODEL_082d2a4baf194e839e4e02d18f5884b1","value":" 565/565 [00:00&lt;00:00, 11.3kB/s]"}},"00749d237a254028ac88de757f831454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67dddc30cbb74b01972ab58f7567f2e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c16bd7467e794b7faba6033a0ad86fd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d1beaedef8c464ea0f178311e9e6a5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9af28a95fe2444ad851e9239910c61f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ee8559284344ff487a0a9724b2ba4d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"082d2a4baf194e839e4e02d18f5884b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f210ce539cc41acb6117b2fba43479d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ad8fd3aed29468793b7fb4dc6746ad9","IPY_MODEL_c80ee0ef61c344fd8e9022a22b71fa76","IPY_MODEL_5c0be7e619584bc1b9f6839237bd62d7"],"layout":"IPY_MODEL_649d43b453004e8ca89f76b1efcb90f2"}},"2ad8fd3aed29468793b7fb4dc6746ad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6e4c1f949744837b57fc81b2c59479a","placeholder":"​","style":"IPY_MODEL_f105e85628aa4d0ea208d13f8970279a","value":"Filter: 100%"}},"c80ee0ef61c344fd8e9022a22b71fa76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a95c61e6917a45b5bd8ad85051235fd9","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_962bee06e12441c19f8bfcb70d2a9191","value":2}},"5c0be7e619584bc1b9f6839237bd62d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0afac3cf856d48c18db28b39d4bab5fa","placeholder":"​","style":"IPY_MODEL_3a2c63f355b24bc8af7f61cba1aecdc5","value":" 2/2 [00:00&lt;00:00,  2.34 examples/s]"}},"649d43b453004e8ca89f76b1efcb90f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6e4c1f949744837b57fc81b2c59479a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f105e85628aa4d0ea208d13f8970279a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a95c61e6917a45b5bd8ad85051235fd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"962bee06e12441c19f8bfcb70d2a9191":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0afac3cf856d48c18db28b39d4bab5fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a2c63f355b24bc8af7f61cba1aecdc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caeabbe927a0461c9a1ea374c6afd641":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_670c37741f4045778403265b3539d9dd","IPY_MODEL_63dc50549fad4757a24d5579b99903e4","IPY_MODEL_b9e0c867975d43e7aacc25c34e85d8de"],"layout":"IPY_MODEL_2407ee6a1d624ae392fbbb6ffd5eaa92"}},"670c37741f4045778403265b3539d9dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cf88202bd7647d2a431602481f36d76","placeholder":"​","style":"IPY_MODEL_b6bb3a5f41ce415893bfbd748ba31373","value":"config.json: 100%"}},"63dc50549fad4757a24d5579b99903e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fde979e2641480d98857419ffaa6f7f","max":723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dac1f567713d4739bc8ccbdddea67b15","value":723}},"b9e0c867975d43e7aacc25c34e85d8de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bc24e8bf0e4474885f8bcf3ec66870c","placeholder":"​","style":"IPY_MODEL_aaf12313ade3459787a00b70adc386c7","value":" 723/723 [00:00&lt;00:00, 18.0kB/s]"}},"2407ee6a1d624ae392fbbb6ffd5eaa92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cf88202bd7647d2a431602481f36d76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6bb3a5f41ce415893bfbd748ba31373":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fde979e2641480d98857419ffaa6f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dac1f567713d4739bc8ccbdddea67b15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bc24e8bf0e4474885f8bcf3ec66870c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaf12313ade3459787a00b70adc386c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2000aa365ddb49569834663b2d12a13b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c78089fa3b394a1f8b4176efb91c1efe","IPY_MODEL_aeb8c0a907c54b6e86bc5938ad901f93","IPY_MODEL_6e4113d959614a37b0b7ac95e0d2ef4d"],"layout":"IPY_MODEL_6a9446d269494a72accec3e85913d4cc"}},"c78089fa3b394a1f8b4176efb91c1efe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81a8427cefb246a2ba52c29e2ce089fc","placeholder":"​","style":"IPY_MODEL_b6b8754d28094ecaa5459922fd29c0fb","value":"model.safetensors: 100%"}},"aeb8c0a907c54b6e86bc5938ad901f93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ad9ebe4f760476691bc8edd77b07eb1","max":269060552,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63e39a1bf393444db0165c0223881dc9","value":269060552}},"6e4113d959614a37b0b7ac95e0d2ef4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7463adfb01044dea1f1868398197562","placeholder":"​","style":"IPY_MODEL_12552c85e96f489bb13912893e9bcb30","value":" 269M/269M [00:03&lt;00:00, 77.1MB/s]"}},"6a9446d269494a72accec3e85913d4cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a8427cefb246a2ba52c29e2ce089fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6b8754d28094ecaa5459922fd29c0fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ad9ebe4f760476691bc8edd77b07eb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e39a1bf393444db0165c0223881dc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7463adfb01044dea1f1868398197562":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12552c85e96f489bb13912893e9bcb30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f242286868f449f0b41853a676fab79c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_874a8689839a4ce7bc4583c795759bf8","IPY_MODEL_852b75a215c74e08bfed4410bc14c40b","IPY_MODEL_884788e2d4d54c7ab038bf815731f809"],"layout":"IPY_MODEL_e0ebcf9ec48c474d97f8fbfa97acc8e8"}},"874a8689839a4ce7bc4583c795759bf8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0131d7befc6c47939df84458d3054f42","placeholder":"​","style":"IPY_MODEL_d0862d02c3ed42bfb99e15c674d8c219","value":"generation_config.json: 100%"}},"852b75a215c74e08bfed4410bc14c40b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9129031e72f1440983e849f4d103bac3","max":156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_072e8fd43fee494faa1fcd0e0a71be67","value":156}},"884788e2d4d54c7ab038bf815731f809":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ec2e0d7a1964735ac20b39ff7d306f0","placeholder":"​","style":"IPY_MODEL_044e561b58b848e5942b3ab9ea72ddd8","value":" 156/156 [00:00&lt;00:00, 3.24kB/s]"}},"e0ebcf9ec48c474d97f8fbfa97acc8e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0131d7befc6c47939df84458d3054f42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0862d02c3ed42bfb99e15c674d8c219":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9129031e72f1440983e849f4d103bac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"072e8fd43fee494faa1fcd0e0a71be67":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ec2e0d7a1964735ac20b39ff7d306f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"044e561b58b848e5942b3ab9ea72ddd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11047625,"sourceType":"datasetVersion","datasetId":6882063},{"sourceId":11052124,"sourceType":"datasetVersion","datasetId":6885472},{"sourceId":11053401,"sourceType":"datasetVersion","datasetId":6886399},{"sourceId":11053670,"sourceType":"datasetVersion","datasetId":6886574},{"sourceId":11066313,"sourceType":"datasetVersion","datasetId":6895837},{"sourceId":11078426,"sourceType":"datasetVersion","datasetId":6904825}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" !pip install trl -q\n !pip install transformers -q\n !pip install vllm -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edQ_08wcg-qQ","outputId":"a02ee925-6755-4931-9ad9-e9661f7c234f","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:50:20.236547Z","iopub.execute_input":"2025-03-25T19:50:20.236835Z","iopub.status.idle":"2025-03-25T19:53:57.638947Z","shell.execute_reply.started":"2025-03-25T19:50:20.236807Z","shell.execute_reply":"2025-03-25T19:53:57.637350Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.4/376.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport wandb\nimport torch.nn.functional as F\n\nfrom typing import List\nfrom dataclasses import dataclass\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\nfrom trl import DataCollatorForCompletionOnlyLM, OnlineDPOConfig, DPOConfig, OnlineDPOTrainer, DPOTrainer, FDivergenceType, FDivergenceConstants\nfrom vllm import LLM, SamplingParams","metadata":{"id":"DR-hjV_0hECm","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:53:57.641014Z","iopub.execute_input":"2025-03-25T19:53:57.641512Z","iopub.status.idle":"2025-03-25T19:54:22.821139Z","shell.execute_reply.started":"2025-03-25T19:53:57.641466Z","shell.execute_reply":"2025-03-25T19:54:22.820456Z"}},"outputs":[{"name":"stdout","text":"INFO 03-25 19:54:22 [__init__.py:239] Automatically detected platform cuda.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"@dataclass\nclass Config:\n  seed: int = 42\n  dataset_path: str = 'HuggingFaceH4/ultrafeedback_binarized'\n  model_name: str = 'HuggingFaceTB/SmolLM-135M-Instruct'\n\n  pair_rm_model: str = \"llm-blender/PairRM\"\n  eval_size: int = 100\n\n  temperature: float = 0.2\n  top_p: float = 0.95\n\n\n  max_seq_len: int = 1024\n\n  output_dir: str = \"/kaggle/working/trained_dpo\"\n  eval_steps: int = 10\n  gradient_accumulation_steps: int = 4\n  gradient_checkpointing: bool = True\n  batch_size: int = 4\n  max_prompt_length: int = 128\n  max_completion_length: int = 256\n  max_steps: int = 200\n  lr_scheduler_type: str = \"cosine\" \n  learning_rate: int = 5e-5\n  logging_steps: int = 10\n  bf16: bool = True # try on P100\n  fp16: bool = False\n  tf32: bool = False\n  beta: float = 5\n  #beta = {0.1, 0.05, 1, 5} in paper\n\n  max_tokens_output: int = 768\n\n  def __post_init__(self):\n    self.num_proc = os.cpu_count() // torch.cuda.device_count() if torch.cuda.is_available() else 1\n    self.model_rlhf = \"/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1\"\n\nconfig = Config()\n# print(config.num_proc)","metadata":{"id":"3P6zhghMiWzM","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:54:22.823056Z","iopub.execute_input":"2025-03-25T19:54:22.823271Z","iopub.status.idle":"2025-03-25T19:54:22.930669Z","shell.execute_reply.started":"2025-03-25T19:54:22.823251Z","shell.execute_reply":"2025-03-25T19:54:22.929710Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def seed_env(seed: int = Config.seed) -> None:\n  random.seed(seed)\n  os.environ['PYTHONHASHSEED'] = str(seed)\n  np.random.seed(seed)\n\ndef seed_torch(seed: int = Config.seed) -> None:\n  torch.manual_seed(seed)\n  torch.cuda.manual_seed(seed)\n  torch.backends.cudnn.deterministic = True\n  torch.backends.cudnn.benchmark = False\n\ndef seed_everything() -> None:\n  \"\"\"Set seeds\"\"\"\n  seed_torch()\n  seed_env()\n\ndef init_wandb() -> None:\n  wandb.login(key=\"abc76743c2934682510c9f2cf81c1896709fe072\")\n  wandb.init(project='DPO, HW2', entity='lulim')\n\nseed_everything()\ninit_wandb()","metadata":{"id":"qaAYRuYSbv2G","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T20:19:48.253309Z","iopub.execute_input":"2025-03-19T20:19:48.253640Z","iopub.status.idle":"2025-03-19T20:20:04.515802Z","shell.execute_reply.started":"2025-03-19T20:19:48.253604Z","shell.execute_reply":"2025-03-19T20:20:04.515090Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlulim\u001b[0m (\u001b[33mturbo-alignment\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlulim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250319_201956-wxpgh5pp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lulim/DPO%2C%20HW2/runs/wxpgh5pp' target=\"_blank\">crimson-sun-16</a></strong> to <a href='https://wandb.ai/lulim/DPO%2C%20HW2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lulim/DPO%2C%20HW2' target=\"_blank\">https://wandb.ai/lulim/DPO%2C%20HW2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lulim/DPO%2C%20HW2/runs/wxpgh5pp' target=\"_blank\">https://wandb.ai/lulim/DPO%2C%20HW2/runs/wxpgh5pp</a>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def filter_dataset(sample: Dataset) -> bool:\n    tokenizer = AutoTokenizer.from_pretrained(\n        config.model_name,\n        padding=\"right\",\n        truncation_side=\"right\",\n        use_fast=True,\n        model_max_length=config.max_seq_len\n    )\n\n    \n    def len_filter(sample: Dataset) -> bool:\n        chosen_conversation = sample[\"chosen\"]\n        tokenized_chosen = tokenizer.apply_chat_template(\n            conversation=chosen_conversation,\n            add_generation_prompt=False,\n            tokenize=True,\n            truncation=False,\n            return_dict=True\n        )\n\n        rejected_conversation = sample[\"rejected\"]\n        tokenized_rejected = tokenizer.apply_chat_template(\n            conversation=chosen_conversation,\n            add_generation_prompt=False,\n            tokenize=True,\n            truncation=False,\n            return_dict=True\n        )\n        return (len(tokenized_chosen[\"input_ids\"]) <= config.max_seq_len) and (len(tokenized_rejected[\"input_ids\"]) <= config.max_seq_len)\n    return len_filter(sample)","metadata":{"id":"PS4CPifxkJYT","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T21:04:44.169595Z","iopub.execute_input":"2025-03-24T21:04:44.169817Z","iopub.status.idle":"2025-03-24T21:04:44.174738Z","shell.execute_reply.started":"2025-03-24T21:04:44.169798Z","shell.execute_reply":"2025-03-24T21:04:44.174070Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"ds = load_dataset(config.dataset_path)\nds[\"train_prefs\"] = ds[\"train_prefs\"].select(range(1000)).filter(filter_dataset, batched=False, num_proc=config.num_proc).shuffle(seed=config.seed)\nds[\"test_prefs\"] = ds[\"test_prefs\"].select(range(1000)).filter(filter_dataset, batched=False, num_proc=config.num_proc).shuffle(seed=config.seed)\n\n# ds[\"train_prefs\"] = ds[\"train_prefs\"].select(range(500)).filter(filter_dataset, batched=False, num_proc=config.num_proc).shuffle(seed=config.seed)\n# ds[\"test_prefs\"] = ds[\"test_prefs\"].select(range(500)).filter(filter_dataset, batched=False, num_proc=config.num_proc).shuffle(seed=config.seed)\nds\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e927f642223a4091b7f6e6e979fd0dd6","a569fa1aee484c08977b587ba6888ca0","9df118328b674ba4ae3fa8133198ff1f","73a0cb0ccce743eb888293886881c868","5b6b4105754c493593f5ebfac9ea8ebd","0da9fe5759ea4d32a0c0ccae3fddb963","bf43c10f41a44fc3b668d4f780421803","fd3e4d72b5e74a27ace1f9b78df28cba","0aced4056a184440b70fc7e17cc141b4","d069d84c4a0d4d62b2cc61b9f24a4dcc","2ba534563e1f4059898ec07736543ef7","bebf518f300f44248d8fe0b6fb605dee","7a4d2507d2684c63b3fa1feaae4d3ced","e8ff6ac7344a48f68c7f9091bd3c053c","547b77c3a7044ec698f2a8b750d0965d","73062d4e94634775b038bdc8bc9f668b","e248db4153f2441199473e2af678c763","08e1bee342dc4cfe98c90a900aaf0256","ad17996822f14317ac95672116a06c3f","fe2b2d25480f4705b9ab373632c5183d","35d7e337fedc46c0ad7c66bba25766d0","050e3582eb764044b2635cb8d2ae5f6b","c7ebdef324154a81871bdecc9f401016","f11486e9b76d4e0685fe93c41a753c2b","e4c77dbaddd24419829698c1de1d414a","453748ff336d4d6fac4fd700755e4479","67106ad799cc4580a7616f1780677143","9549bd687a9a4db2a9f8cc21e74e380a","8d822f2d4c694addb95a995ab4a10283","5df2b31dfddf43eb85785e72fec95955","8e755ce1ffda4628a09d5830a1f76969","c7e8194204aa4f6f9944e93014bb275c","cd370760f38d4ccfb9ea4ee495c91de0","1b1e2b8ed951472b9e107d846f7eeba6","914b581b0264419ca86c496c70e1bad1","8fb4d1c158454bd581453e1f7417b584","16f30199b93c4924baa566833e3bac3f","287ddf54c75e4f08a7a9f062eac256b7","24c1a81f62dc4ea9b7cf60313658dce3","bd488aca96654e0da4bf2913411c1ddd","64423133632d4912b0e32d137e416d06","d01132e9590940938a4f55933d541370","ef27e1517b074753921d45a9a037c1e9","eab872731fb446ecb5fcdbdf4165b44e","95dbb7a1097e453385866c1ed78f404c","f32d2624c382447c9488c8aa7076fea2","682b2dfd019a45f195e259f749d1beb0","87af11d01c7a46eabd4b429d2fce36db","0609d3911d2740d8bde03aadec88a070","418b074d096d4f2da523e0926828950d","7ac32880e0bd495daeec72f492047e39","1df06b3d63e44b168ebb7a1677a1c869","8d5de84a102345c4b04fecad9ed3bf43","e28591037f8b41229536f0b257c0727b","31964ae9f7a24392ad8c02ea31ed3c8f","52af5e945cbc41bfb9b88bc311c2f7b3","145e927ffc0140c29ef66d6b1e8d9878","9685a6e3c133402aa476ade0c3848314","eedc9337623d4fd294e9857620759118","bb940b71e76749fb90b87a2c03b0b011","998b7e5238284bc8991a0f7d5d8454a5","dc38e7312ff649b3baddd5b4c9baad6e","a6218019794f4087963087cbe647e711","be3b8e1f0d3a483589036956e88fe819","dde6c4ed1f544596b6db308b9b2438e0","ba817e93385e474cb30ec30d443a1f46","01024fe41e8045a19cce88a86ae5ee7e","ebb0fff3259a4345b7bb8f05552c09b7","8330dc00da4844cc85eb030ae54dcdc3","afcafa0a748e40c4a06d87771c42ab69","81fa489fca5942ef931cfde0e03e7a28","6c5ba2eae91a4dca8d888a25e1049edc","20ccd2c5b78b4f2abb1fc22690029554","7bc81ba58e0b493da4828bf6fbd4d3d8","eaae8772ef324b5a93073615ad9fa28f","d9ff1b2d565b493a84095cbd056daa9e","5df6da418ec745a78305ee1ee9ebe4e6","58824426d96e4a48bdefce96226fad55","956feae422434e0fa18610cda32122b9","8a95337d958f4566898663a5524f0796","f0a1361cc93a4635b5382baa2fac40f1","83d1ec0ad29648619723e415fbb846e6","c44e8ab485044969afb75ae6e7aa7329","7cfcf73bdcea4490b9696b3dd83373ff","b4f6e3dea1ee41228c3339df265c8fb3","31d384f8bbf14c60a90d72517dfdd6be","df3c3ef86fab4dbaba278f14cc3de605","3bbf29122a2548cf96a269e1376b3cb3","3e7f2cc702324d899ce4c40c7bc60a1d","d7dda8e620414d839492139a806685f8","faac089ac7004c9a8044a9d19fbe8b7e","9114e2f2068c4feea30f331f488264c8","09b947d1a1f043ab82cc6c5c444b9e18","a3b1a7c850df41adbc434041c19a7d28","0778459f77354d419bf35db506037260","659d4ccdd3ad4fd3b613fc536085edfa","922b1a74e35144a1b527bd0d3da9339c","197a5429406c4f2eaf21d4b73b8d60c9","7f68b1e149e64577b8a4232d9fcc62e8","177f8323cdbe489dae691c8570cb1bc3","ee518d886b6d44a0afe500febb7d6ae5","e4ef8b9c49264ca582e14b2d8291df0e","e3d9a93fb0d64b968961842cf7e659ab","eb5d5314ed034b6389c0d87363d27c48","fc73e60b36df464fb4250ddc6eb5029f","d57d0945653b41b3a5e3c2a514f463bf","6326552b6ea04a5794bb39c6b2c7d6b0","bfa350cd7e47404bb1190171182068b9","d0226a44084d4f33802c24d22a2b5cf3","b9e1dc5044c74c28ab841cad2f477124","89b7298d3cb542b7ae9686d15b8cdfd1","a833fec7cc5e439a96b961a21fa96981","8e6f2c7d447a407e8a6f37eee22203c9","f301a697d5e64ac7aee03acbe94b2684","cee98ee1c7b5401d9ff6ba93bffc444f","878a8b06dc244c2596ff3f31c6045e3c","4e15c064c0b24e219c09a3d2dbbb239c","d11b48b63c12496b9931b496479532a1","c22ae20175f54c0baed28935af89f658","0be0cb2b309c41aca96f62a49cd3c400","9a83ecf2e2994828bf4b6c6298817fd8","05920b40c18b4cdc93fd19daf6e7b3e0","3abee125688b4764ad865370658bc509","3d6a67adf1a240aea631109d548bb170","401a91dba2854e698d13e607b8ff8955","21b1ca87613d4a7882a6ba604884c57d","2f87713d1927459dac5cbdf7d328ccae","f2de6bee8d8043c7b8759ab4828efc10","169432aebbf64fca82c4c29bbcdc6735","a8af38abb76a4bde9310961b017cb4ea","ea5df22658e64b65bef512f63671a371","0a57898d58ed4aca913e0939744e257f","51fc2ff8a5964b8eaee6f573b7481d4f","461ead21de994b7baad39a385d8a6ff6","87ed781c75ed42f98b44b12d212777c6","3424b68cf5604acbaa496d12d9a5425c","ff0960181919410b89ade334ae1eef16","e9d0c2ee1f9d44ff8a0512482497b6d3","329cea7a3c7142f39d2480ecabb4b48e","c5c194288a194b0a91fc32cbf0a5ac6f","df8ff18c36854bfd8ac1ff8730457715","3df98b4335a44ee58c42dd8e007b12e0","f587e3df16ef4dcdb3334cff6d42ffa9","daa6ed54616e4954bb5c0f3414dd2283","3ed01baf07bf48cda752d37e2931ede6","c042ae5fa9034ccd89b79aa9cfe2ab36","76effb0e0ae949a08d377c9303f00c19","de4880b8d4d140f990bd8006c64884f0","bd8d61beeb794779a84ff7a0e4add47f","80b59d4d4c98492ba6f3bd32c71fa9c8","3402e790a84f4136881cd9dd42d7f36f","8838687703fb49cba466c304dec458b3","9272a2a1ba3e43c58b366a21ac77f3d9","04710cdf4f3b4800aa22689a459a3e1d","603da3e19b6c4661a4de8439514d5d7c","74096d154b974ef2b98d11bc36e41581","dd353a3488fd4a70b39ced2117d4a5cb","b2a5f586772f47b1ac26c4248da9b398","566e57441f6746df9ab2a69ea122942c","382dca2369ae49f09196ea2523f57b75","df36fdfb35ea4820a888f936a7d6637c","8fb6f916bcfe42f5b3a5aa58a60b56a6","79aee0db4bb24a90bce23ee2e5905a62","76a5127824ff4d40b78e4003a7fbe750","60567efe431144bf89e736b6e799cd3f","d046f2a89ce04e508ce79ff2f92663dc","d5f7ac4e0acf4ca18c078d50af6952c4","8f42df5acaf345648261345fbce5903d","be23a41378f4450e8bc749445f6bfc6a","c73c2b0754124455bd476003b2181883","46b2afc5429d4e69876618f5aae79aa6","f7ac6ddd0682402fac9d7c79aa078588","349f0d30736d489c9b826feda69d3522","a8b23c322f95448281edfcf6c872d866","17cc436828e0443d835c67545c3ff38a","f71ad3a0e2c94e6aa50915deecb2003b","bb0fabdfd5614d668101c2b59ba5b8df","2bb2e8d34c044458b61055a737248548","a2f0dfaf572b4656be8ca835cc123513","334b6de2aa134d029bb99fc57c2d48b2","d2f39459e8ef4239a419ec84bec0028e","a0531e5b5a2f4c3f935a09cfa8659a08","3f0681bf10b04c95b6fe5422cadfe6a2","bd5d26b821694128a123857b51d16665","fe613f4b736c4fbdaa26257e7c9bc398","36e19da0df9944a2a4395fa39a842782","ac7772aa53374ed1b74487b13e9e72fe","c994b4d52b334841a432d2aaa7550603","8030eaa04e024ecbb896054e18aae7c0","0712c4fbfb0c467cadbc8d564ded637d","2da01bb85de94e21ad18e2ce82db0019","00749d237a254028ac88de757f831454","67dddc30cbb74b01972ab58f7567f2e7","c16bd7467e794b7faba6033a0ad86fd2","1d1beaedef8c464ea0f178311e9e6a5f","9af28a95fe2444ad851e9239910c61f8","6ee8559284344ff487a0a9724b2ba4d5","082d2a4baf194e839e4e02d18f5884b1","4f210ce539cc41acb6117b2fba43479d","2ad8fd3aed29468793b7fb4dc6746ad9","c80ee0ef61c344fd8e9022a22b71fa76","5c0be7e619584bc1b9f6839237bd62d7","649d43b453004e8ca89f76b1efcb90f2","a6e4c1f949744837b57fc81b2c59479a","f105e85628aa4d0ea208d13f8970279a","a95c61e6917a45b5bd8ad85051235fd9","962bee06e12441c19f8bfcb70d2a9191","0afac3cf856d48c18db28b39d4bab5fa","3a2c63f355b24bc8af7f61cba1aecdc5"]},"id":"RGZfTbrwhF-Z","outputId":"479296c6-0cf6-4e21-b78d-8aba86e88c64","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T21:04:44.175389Z","iopub.execute_input":"2025-03-24T21:04:44.175585Z","iopub.status.idle":"2025-03-24T21:04:48.700623Z","shell.execute_reply.started":"2025-03-24T21:04:44.175567Z","shell.execute_reply":"2025-03-24T21:04:48.699105Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f319e7c808af4474a4588287cc297f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_prefs-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74a6bc7ec8c94553a0627ba18cb0008b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test_prefs-00000-of-00001.parquet:   0%|          | 0.00/7.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5218f85d82cf4ed4ab78dd61a91b95af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test_sft-00000-of-00001.parquet:   0%|          | 0.00/3.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5edeb5267f914f25bb149dd7ac8ee230"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-32b5888e2a1d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_prefs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_prefs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_prefs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_prefs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ds[\"train_prefs\"] = ds[\"train_prefs\"].select(range(500)).filter(filter_dataset, batched=False, num_proc=config.num_proc).shuffle(seed=config.seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2151\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   2152\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                         \u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_proc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                     self._download_and_prepare(\n\u001b[0m\u001b[1;32m    925\u001b[0m                         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                         \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0msplit_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0msplit_generators_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_split_generators_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m         \u001b[0msplit_generators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msplit_generators_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# Checksums verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/parquet/parquet.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"At least one data file must be specified, but got data_files={self.config.data_files}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_on_the_fly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mextracted_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_recorded_sizes_checksums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstack_multiprocessing_download_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             downloaded_path_or_paths = map_nested(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0mdownload_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0murl_or_urls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         mapped = [\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         mapped = [\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         ]\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    397\u001b[0m             }\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m             }\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     ):\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapped_item\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapped_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     ):\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapped_item\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapped_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    217\u001b[0m             )\n\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0murl_or_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             return [\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0murl_or_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# append the relative path to the base_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0murl_or_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_or_path_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracked_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             ).resolve_path(url_or_filename)\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 output_path = huggingface_hub.HfApi(\n\u001b[0m\u001b[1;32m    183\u001b[0m                     \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHF_ENDPOINT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5246\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5248\u001b[0;31m         return hf_hub_download(\n\u001b[0m\u001b[1;32m   5249\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5250\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         _download_to_tmp_and_move(\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".incomplete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0mdestination_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0m_check_disk_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m         http_get(\n\u001b[0m\u001b[1;32m   1548\u001b[0m             \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mnew_resume_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOWNLOAD_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     def _raw_read(\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    config.model_name,\n    torch_dtype=torch.bfloat16\n)\ntokenizer = AutoTokenizer.from_pretrained(\n        config.model_name,\n        padding=\"right\",\n        truncation_side=\"right\",\n        use_fast=True,\n        model_max_length=config.max_seq_len\n)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["caeabbe927a0461c9a1ea374c6afd641","670c37741f4045778403265b3539d9dd","63dc50549fad4757a24d5579b99903e4","b9e0c867975d43e7aacc25c34e85d8de","2407ee6a1d624ae392fbbb6ffd5eaa92","0cf88202bd7647d2a431602481f36d76","b6bb3a5f41ce415893bfbd748ba31373","4fde979e2641480d98857419ffaa6f7f","dac1f567713d4739bc8ccbdddea67b15","1bc24e8bf0e4474885f8bcf3ec66870c","aaf12313ade3459787a00b70adc386c7","2000aa365ddb49569834663b2d12a13b","c78089fa3b394a1f8b4176efb91c1efe","aeb8c0a907c54b6e86bc5938ad901f93","6e4113d959614a37b0b7ac95e0d2ef4d","6a9446d269494a72accec3e85913d4cc","81a8427cefb246a2ba52c29e2ce089fc","b6b8754d28094ecaa5459922fd29c0fb","8ad9ebe4f760476691bc8edd77b07eb1","63e39a1bf393444db0165c0223881dc9","e7463adfb01044dea1f1868398197562","12552c85e96f489bb13912893e9bcb30","f242286868f449f0b41853a676fab79c","874a8689839a4ce7bc4583c795759bf8","852b75a215c74e08bfed4410bc14c40b","884788e2d4d54c7ab038bf815731f809","e0ebcf9ec48c474d97f8fbfa97acc8e8","0131d7befc6c47939df84458d3054f42","d0862d02c3ed42bfb99e15c674d8c219","9129031e72f1440983e849f4d103bac3","072e8fd43fee494faa1fcd0e0a71be67","9ec2e0d7a1964735ac20b39ff7d306f0","044e561b58b848e5942b3ab9ea72ddd8"]},"id":"OrbovhCHhG0R","outputId":"b02a66a5-eedf-4ec8-ce67-feee0db8716a","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:03:14.871124Z","iopub.execute_input":"2025-03-19T21:03:14.871475Z","iopub.status.idle":"2025-03-19T21:03:18.039025Z","shell.execute_reply.started":"2025-03-19T21:03:14.871449Z","shell.execute_reply":"2025-03-19T21:03:18.038238Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f28fb8da248412097c0dde47f6c3dc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e9951117b4b42bd959d278c77eb46bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"795907b2075b4cd89e21d5387ef4baaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dae85168b91a4bbe8f69587626e4dbed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b19f7f6b15a14452acbb71dc6f0d1432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d215c86533154d66b12cbb06e6d6ac01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"396db98d4d814dbda5335f17413a52e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/565 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f858ff23fd6445e8bea81d70e501cc09"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Vanila DPO","metadata":{}},{"cell_type":"code","source":"config.output_dir = config.output_dir + f\"_beta_{config.beta}\"\nconfig.output_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T20:10:35.307150Z","iopub.execute_input":"2025-03-18T20:10:35.307354Z","iopub.status.idle":"2025-03-18T20:10:35.313427Z","shell.execute_reply.started":"2025-03-18T20:10:35.307336Z","shell.execute_reply":"2025-03-18T20:10:35.312332Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/trained_dpo_beta_5'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"training_args = DPOConfig(\n    output_dir=config.output_dir,\n    eval_strategy=\"steps\",\n    eval_steps=config.eval_steps,\n    # report_to=\"wandb\",\n    report_to=\"none\",\n    gradient_accumulation_steps=config.gradient_accumulation_steps,\n    gradient_checkpointing=config.gradient_checkpointing,\n    per_device_train_batch_size=config.batch_size,\n    per_device_eval_batch_size=config.batch_size,\n    max_prompt_length=config.max_prompt_length,\n    max_completion_length=config.max_completion_length,\n    max_steps=config.max_steps,\n    lr_scheduler_type=config.lr_scheduler_type,\n    learning_rate=config.learning_rate,\n    logging_steps=config.logging_steps,\n    beta=config.beta,\n    fp16=config.fp16,\n    tf32=config.tf32,\n    bf16=config.bf16\n)\ndpo_trainer = DPOTrainer(\n    model=model,\n    processing_class=tokenizer,\n    args=training_args,\n    train_dataset=ds[\"train_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"]),\n    eval_dataset=ds[\"test_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"])\n)\ndpo_trainer.train()\ndpo_trainer.save_model()","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":349},"id":"O01n7bvkhG2x","outputId":"eae996ff-01df-492d-e217-0106bc031804","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T20:11:14.765018Z","iopub.execute_input":"2025-03-18T20:11:14.765364Z","iopub.status.idle":"2025-03-18T21:01:40.220655Z","shell.execute_reply.started":"2025-03-18T20:11:14.765338Z","shell.execute_reply":"2025-03-18T21:01:40.219882Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Extracting prompt in train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9ca3c2842340af914abceb965a6511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e28286a7897a4f6f9ef6c12ebbcc087b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51fb0ed3e3894da4a2ead22107691d49"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting prompt in eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f34e1bca1c743508ef07c4309d5bd10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbed0dafeb2b440fb3cbaf197fdfc9d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a5fa9e818f64b0d95c2ef68bea6ed5c"}},"metadata":{}},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 50:12, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/chosen</th>\n      <th>Logps/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Logits/rejected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.831900</td>\n      <td>2.126009</td>\n      <td>-1.241936</td>\n      <td>-1.773510</td>\n      <td>0.542918</td>\n      <td>0.531574</td>\n      <td>-295.413422</td>\n      <td>-289.308014</td>\n      <td>-0.505283</td>\n      <td>-0.338918</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.586400</td>\n      <td>2.143726</td>\n      <td>-0.537510</td>\n      <td>-1.217720</td>\n      <td>0.531116</td>\n      <td>0.680210</td>\n      <td>-295.272522</td>\n      <td>-289.196808</td>\n      <td>-0.479461</td>\n      <td>-0.313732</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.168700</td>\n      <td>2.167031</td>\n      <td>0.418590</td>\n      <td>-0.230132</td>\n      <td>0.547210</td>\n      <td>0.648721</td>\n      <td>-295.081299</td>\n      <td>-288.999298</td>\n      <td>-0.459458</td>\n      <td>-0.293470</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.179700</td>\n      <td>2.164281</td>\n      <td>0.700673</td>\n      <td>0.172875</td>\n      <td>0.520386</td>\n      <td>0.527798</td>\n      <td>-295.024902</td>\n      <td>-288.918701</td>\n      <td>-0.448208</td>\n      <td>-0.282238</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.827200</td>\n      <td>2.067701</td>\n      <td>0.981626</td>\n      <td>0.299071</td>\n      <td>0.543991</td>\n      <td>0.682554</td>\n      <td>-294.968719</td>\n      <td>-288.893463</td>\n      <td>-0.451606</td>\n      <td>-0.285932</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.873200</td>\n      <td>1.960009</td>\n      <td>0.628709</td>\n      <td>-0.262658</td>\n      <td>0.548283</td>\n      <td>0.891367</td>\n      <td>-295.039337</td>\n      <td>-289.005829</td>\n      <td>-0.462894</td>\n      <td>-0.297051</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.329900</td>\n      <td>2.125365</td>\n      <td>0.248159</td>\n      <td>-0.383990</td>\n      <td>0.545064</td>\n      <td>0.632149</td>\n      <td>-295.115417</td>\n      <td>-289.030090</td>\n      <td>-0.467956</td>\n      <td>-0.301630</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.547700</td>\n      <td>2.121719</td>\n      <td>0.374749</td>\n      <td>-0.416980</td>\n      <td>0.555794</td>\n      <td>0.791729</td>\n      <td>-295.090057</td>\n      <td>-289.036682</td>\n      <td>-0.471225</td>\n      <td>-0.305130</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.360200</td>\n      <td>1.952107</td>\n      <td>0.306544</td>\n      <td>-0.715746</td>\n      <td>0.550429</td>\n      <td>1.022291</td>\n      <td>-295.103729</td>\n      <td>-289.096405</td>\n      <td>-0.464510</td>\n      <td>-0.298507</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.508800</td>\n      <td>2.127689</td>\n      <td>0.101115</td>\n      <td>-0.648776</td>\n      <td>0.541846</td>\n      <td>0.749890</td>\n      <td>-295.144806</td>\n      <td>-289.083008</td>\n      <td>-0.470504</td>\n      <td>-0.305494</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.412000</td>\n      <td>2.045489</td>\n      <td>0.104992</td>\n      <td>-0.735679</td>\n      <td>0.540773</td>\n      <td>0.840671</td>\n      <td>-295.144043</td>\n      <td>-289.100403</td>\n      <td>-0.472196</td>\n      <td>-0.305822</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.391500</td>\n      <td>2.061300</td>\n      <td>0.100183</td>\n      <td>-0.617833</td>\n      <td>0.541846</td>\n      <td>0.718016</td>\n      <td>-295.144989</td>\n      <td>-289.076843</td>\n      <td>-0.475054</td>\n      <td>-0.309719</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.131400</td>\n      <td>1.980351</td>\n      <td>0.118539</td>\n      <td>-0.848248</td>\n      <td>0.557940</td>\n      <td>0.966787</td>\n      <td>-295.141327</td>\n      <td>-289.122925</td>\n      <td>-0.474474</td>\n      <td>-0.308887</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.170000</td>\n      <td>2.102456</td>\n      <td>0.026328</td>\n      <td>-0.727614</td>\n      <td>0.538627</td>\n      <td>0.753943</td>\n      <td>-295.159760</td>\n      <td>-289.098785</td>\n      <td>-0.472982</td>\n      <td>-0.307703</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.199100</td>\n      <td>2.095366</td>\n      <td>-0.147706</td>\n      <td>-0.913939</td>\n      <td>0.535408</td>\n      <td>0.766233</td>\n      <td>-295.194580</td>\n      <td>-289.136108</td>\n      <td>-0.473100</td>\n      <td>-0.307395</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.160500</td>\n      <td>2.014122</td>\n      <td>0.021518</td>\n      <td>-1.058400</td>\n      <td>0.549356</td>\n      <td>1.079918</td>\n      <td>-295.160736</td>\n      <td>-289.164978</td>\n      <td>-0.473567</td>\n      <td>-0.307449</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.274800</td>\n      <td>1.982256</td>\n      <td>-0.012246</td>\n      <td>-0.977847</td>\n      <td>0.545064</td>\n      <td>0.965601</td>\n      <td>-295.167450</td>\n      <td>-289.148865</td>\n      <td>-0.474668</td>\n      <td>-0.309745</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.154300</td>\n      <td>2.024846</td>\n      <td>0.021419</td>\n      <td>-0.854490</td>\n      <td>0.554721</td>\n      <td>0.875908</td>\n      <td>-295.160736</td>\n      <td>-289.124176</td>\n      <td>-0.475029</td>\n      <td>-0.308584</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.251700</td>\n      <td>1.991580</td>\n      <td>-0.006194</td>\n      <td>-1.099223</td>\n      <td>0.556867</td>\n      <td>1.093029</td>\n      <td>-295.166290</td>\n      <td>-289.173096</td>\n      <td>-0.476704</td>\n      <td>-0.310835</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.169900</td>\n      <td>1.968847</td>\n      <td>0.125139</td>\n      <td>-0.977976</td>\n      <td>0.566524</td>\n      <td>1.103115</td>\n      <td>-295.140015</td>\n      <td>-289.148865</td>\n      <td>-0.476611</td>\n      <td>-0.311105</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"!zip -r /kaggle/working/trained_dpo_beta_5.zip /kaggle/working/trained_dpo_beta_5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T21:01:40.221700Z","iopub.execute_input":"2025-03-18T21:01:40.221961Z","iopub.status.idle":"2025-03-18T21:03:37.445411Z","shell.execute_reply.started":"2025-03-18T21:01:40.221937Z","shell.execute_reply":"2025-03-18T21:03:37.444669Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/trained_dpo_beta_5/ (stored 0%)\n  adding: kaggle/working/trained_dpo_beta_5/model.safetensors (deflated 21%)\n  adding: kaggle/working/trained_dpo_beta_5/tokenizer.json (deflated 82%)\n  adding: kaggle/working/trained_dpo_beta_5/merges.txt (deflated 55%)\n  adding: kaggle/working/trained_dpo_beta_5/tokenizer_config.json (deflated 85%)\n  adding: kaggle/working/trained_dpo_beta_5/config.json (deflated 46%)\n  adding: kaggle/working/trained_dpo_beta_5/training_args.bin (deflated 52%)\n  adding: kaggle/working/trained_dpo_beta_5/vocab.json (deflated 59%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/ (stored 0%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/optimizer.pt (deflated 24%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/model.safetensors (deflated 21%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/rng_state.pth (deflated 25%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/tokenizer.json (deflated 82%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/merges.txt (deflated 55%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/tokenizer_config.json (deflated 85%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/config.json (deflated 46%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/training_args.bin (deflated 52%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/vocab.json (deflated 59%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/scheduler.pt (deflated 56%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/trainer_state.json (deflated 77%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/special_tokens_map.json (deflated 71%)\n  adding: kaggle/working/trained_dpo_beta_5/checkpoint-200/generation_config.json (deflated 30%)\n  adding: kaggle/working/trained_dpo_beta_5/special_tokens_map.json (deflated 71%)\n  adding: kaggle/working/trained_dpo_beta_5/generation_config.json (deflated 30%)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import os \nfrom IPython.display import FileLink\n\n\nos.chdir(r'/kaggle/working')\nFileLink(r'trained_dpo_beta_5.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T21:03:37.446872Z","iopub.execute_input":"2025-03-18T21:03:37.447109Z","iopub.status.idle":"2025-03-18T21:03:37.453754Z","shell.execute_reply.started":"2025-03-18T21:03:37.447088Z","shell.execute_reply":"2025-03-18T21:03:37.453096Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/trained_dpo_beta_5.zip","text/html":"<a href='trained_dpo_beta_5.zip' target='_blank'>trained_dpo_beta_5.zip</a><br>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# Pair eval","metadata":{"id":"BH59qzjPanD_"}},{"cell_type":"code","source":"!pip install git+https://github.com/yuchenlin/LLM-Blender.git -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:54:22.931874Z","iopub.execute_input":"2025-03-25T19:54:22.932094Z","iopub.status.idle":"2025-03-25T19:54:33.132092Z","shell.execute_reply.started":"2025-03-25T19:54:22.932074Z","shell.execute_reply":"2025-03-25T19:54:33.131057Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for llm_blender (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import llm_blender\nfrom llm_blender.pair_ranker.pairrm import DebertaV2PairRM\n\npair_rm = llm_blender.Blender()\npair_rm.loadranker(config.pair_rm_model)\n\nds = load_dataset(config.dataset_path)\nnp.random.seed(config.seed)\neval_idxs = np.random.randint(low=0, high=len(ds), size=config.eval_size)\n# print(f\"{eval_idxs}\")\nds_eval = ds[\"test_sft\"].select(eval_idxs).select_columns([\"prompt\"]).shuffle(seed=config.seed)\nds_eval = [sample[\"prompt\"] for sample in ds_eval]\nds_eval[0]","metadata":{"id":"Vqce-TyGhG5K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"812134cd-bc6c-4fcd-e102-d8c53702eb39","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:54:33.133231Z","iopub.execute_input":"2025-03-25T19:54:33.133540Z","iopub.status.idle":"2025-03-25T19:55:08.803418Z","shell.execute_reply.started":"2025-03-25T19:54:33.133517Z","shell.execute_reply":"2025-03-25T19:55:08.802474Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b038f93d7e1431e824ba83b8da5948c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b04e818621f946718b14600ddff4e575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eb900bb00994ceaa015853f613d2cb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/130 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b57e9451c20415795afa463888b89d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/13.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92e439cdd744461eb78a207e3dffe1fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d0b41692e624369b2ed65de48f7ed45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a048af32474fc7876bae7fc0b512f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fd2339fcb3d49068c145fd162105d69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132ad378c78e44359141302d31a4d8f5"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/dataclasses_json/core.py:201: RuntimeWarning: 'NoneType' object value of non-optional type load_checkpoint detected when decoding RankerConfig.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/dataclasses_json/core.py:201: RuntimeWarning: 'NoneType' object value of non-optional type device detected when decoding RankerConfig.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b6de8eea7bd42e2b5e97996032d42b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a279988deab456bade638a89967f09a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fea407a9aea4027941b8995a6be65df"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d12dced499445c6a630fcca988ffb2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa407678e5840cbbaf3fc14a5d66083"}},"metadata":{}},{"name":"stdout","text":"Successfully loaded ranker from  /root/.cache/huggingface/hub/llm-blender/PairRM\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/6.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8173a47f884a4a57bc7e6f1f471df843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_prefs-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74a32822c2f840f2ae55f140547fa85f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test_prefs-00000-of-00001.parquet:   0%|          | 0.00/7.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"981a5d3f6da94d7b8d594cec52ad9ba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test_sft-00000-of-00001.parquet:   0%|          | 0.00/3.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53a8b992b29a413fbb59d3459b52c5eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_gen-00000-of-00001.parquet:   0%|          | 0.00/184M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84e74c985d4c4001817ef088c87e2eef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test_gen-00000-of-00001.parquet:   0%|          | 0.00/3.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c1558cb31c04293b0145dd6e3b7faea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_prefs split:   0%|          | 0/61135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0814e7d233b844d39efc224207fe0d7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_sft split:   0%|          | 0/61135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"114f5c14676248d5a28d5231ba6f320e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_prefs split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568b5d2cebd24b9a9dcbac746106b868"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_sft split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e623134c7e2540aa9f83548e7154861f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_gen split:   0%|          | 0/61135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"442ec77162714906ade0cd22a022d761"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_gen split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4694bd985a134482b1e15832bc7b1667"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'Evaluate the extent to which web usability is affected by various design styles, including color scheme, typography, layout, and navigation. Provide specific examples and empirical evidence to support your analysis.'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def give_text_answers(prompts, pair_rm_model, model_sft, model_rlhf, sampling_params):\n  model_sft = LLM(model=model_sft, dtype=\"float16\", gpu_memory_utilization=0.4)\n  model_rlhf = LLM(model=model_rlhf, dtype=\"float16\", gpu_memory_utilization=0.4)\n\n  outputs_sft = model_sft.generate(prompts, sampling_params)\n  outputs_rlhf = model_rlhf.generate(prompts, sampling_params)\n\n  only_outputs_sft = [output.outputs[0].text for output in outputs_sft]\n  only_outputs_rlhf = [output.outputs[0].text for output in outputs_rlhf]\n\n  # print(outputs_sft)\n  # print(outputs_sft[0]) \n  only_outputs_sft_logprobs = [output.outputs[0].logprobs for output in outputs_sft]\n  only_outputs_rlhf_logprobs = [output.outputs[0].logprobs for output in outputs_rlhf]\n  # print(outputs_rlhf)\n  comparison_results = pair_rm_model.compare(prompts, only_outputs_rlhf, only_outputs_sft, \n                                             batch_size=2) # A > B\n  # scores_sft = pair_rm.compare(inputs, only_outputs_sft, , batch_size=2)\n\n  return comparison_results, only_outputs_rlhf, only_outputs_sft, \\\n        only_outputs_rlhf_logprobs, only_outputs_sft_logprobs","metadata":{"id":"jWgbE6EkhG7k","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:55:08.804438Z","iopub.execute_input":"2025-03-25T19:55:08.805314Z","iopub.status.idle":"2025-03-25T19:55:08.811976Z","shell.execute_reply.started":"2025-03-25T19:55:08.805288Z","shell.execute_reply":"2025-03-25T19:55:08.811286Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"sampling_params = SamplingParams(temperature=config.temperature, top_p=config.top_p,\n                                 max_tokens=config.max_tokens_output, \n                                 logprobs=20\n)\ncomparison_results, outputs_rlhf, outputs_sft, only_outputs_rlhf_logprobs, only_outputs_sft_logprobs = give_text_answers(ds_eval, pair_rm, config.model_name, config.model_rlhf, sampling_params) # for debug equal models","metadata":{"id":"tar97SyjdeId","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T21:05:42.515348Z","iopub.execute_input":"2025-03-24T21:05:42.515708Z","iopub.status.idle":"2025-03-24T21:11:01.122096Z","shell.execute_reply.started":"2025-03-24T21:05:42.515673Z","shell.execute_reply":"2025-03-24T21:11:01.121097Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56d5e83ce3c454884b612bcb839eeda"}},"metadata":{}},{"name":"stdout","text":"WARNING 03-24 21:05:46 [config.py:2599] Casting torch.bfloat16 to torch.float16.\nINFO 03-24 21:06:00 [config.py:583] This model supports multiple tasks: {'generate', 'score', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\nWARNING 03-24 21:06:00 [arg_utils.py:1765] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \nINFO 03-24 21:06:00 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.1) with config: model='HuggingFaceTB/SmolLM-135M-Instruct', speculative_config=None, tokenizer='HuggingFaceTB/SmolLM-135M-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=HuggingFaceTB/SmolLM-135M-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b628eda099499a955a929bd9419332"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90e2a2792ff543458e85ce631a333d6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38fe9c15dda34b7ab5260362d83ed168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4cb918927ee4fbbafacc71afd2d2c22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/565 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"023bb5b5345b4a36a05ee58eb822042c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e21cdde62164088bfca1e8505637c10"}},"metadata":{}},{"name":"stdout","text":"INFO 03-24 21:06:03 [cuda.py:234] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 03-24 21:06:03 [cuda.py:282] Using XFormers backend.\nINFO 03-24 21:06:24 [parallel_state.py:967] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\nINFO 03-24 21:06:24 [model_runner.py:1110] Starting to load model HuggingFaceTB/SmolLM-135M-Instruct...\nINFO 03-24 21:06:24 [weight_utils.py:257] Using model weights format ['*.safetensors']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b7afe08a2b342e38c142f2f263a260e"}},"metadata":{}},{"name":"stdout","text":"INFO 03-24 21:06:25 [weight_utils.py:273] Time spent downloading weights for HuggingFaceTB/SmolLM-135M-Instruct: 1.176216 seconds\nINFO 03-24 21:06:25 [weight_utils.py:307] No model.safetensors.index.json found in remote.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17c542581a1456084b21a779f6db5bf"}},"metadata":{}},{"name":"stdout","text":"INFO 03-24 21:06:26 [loader.py:429] Loading weights took 0.27 seconds\nINFO 03-24 21:06:26 [model_runner.py:1146] Model loading took 0.2547 GB and 1.961097 seconds\nINFO 03-24 21:06:27 [worker.py:267] Memory profiling takes 0.82 seconds\nINFO 03-24 21:06:27 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.40) = 5.90GiB\nINFO 03-24 21:06:27 [worker.py:267] model weights take 0.25GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 0.46GiB; the rest of the memory reserved for KV Cache is 5.14GiB.\nINFO 03-24 21:06:28 [executor_base.py:111] # cuda blocks: 14969, # CPU blocks: 11650\nINFO 03-24 21:06:28 [executor_base.py:116] Maximum concurrency for 2048 tokens per request: 116.95x\nINFO 03-24 21:06:34 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","output_type":"stream"},{"name":"stderr","text":"Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:34<00:00,  1.00it/s]","output_type":"stream"},{"name":"stdout","text":"INFO 03-24 21:07:09 [model_runner.py:1570] Graph capturing finished in 35 secs, took 0.21 GiB\nINFO 03-24 21:07:09 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 42.62 seconds\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING 03-24 21:07:09 [config.py:2599] Casting torch.bfloat16 to torch.float16.\nINFO 03-24 21:07:09 [config.py:583] This model supports multiple tasks: {'generate', 'score', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\nINFO 03-24 21:07:09 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.1) with config: model='/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1', speculative_config=None, tokenizer='/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \nINFO 03-24 21:07:10 [model_runner.py:1110] Starting to load model /kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d4e6c5bac614c2eb62c523f8a18703e"}},"metadata":{}},{"name":"stdout","text":"INFO 03-24 21:07:13 [loader.py:429] Loading weights took 3.13 seconds\nINFO 03-24 21:07:14 [model_runner.py:1146] Model loading took 0.2548 GB and 3.187235 seconds\nINFO 03-24 21:07:15 [worker.py:267] Memory profiling takes 0.64 seconds\nINFO 03-24 21:07:15 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.40) = 5.90GiB\nINFO 03-24 21:07:15 [worker.py:267] model weights take 0.25GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.45GiB; the rest of the memory reserved for KV Cache is 5.19GiB.\nINFO 03-24 21:07:15 [executor_base.py:111] # cuda blocks: 15129, # CPU blocks: 11650\nINFO 03-24 21:07:15 [executor_base.py:116] Maximum concurrency for 2048 tokens per request: 118.20x\nINFO 03-24 21:07:22 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","output_type":"stream"},{"name":"stderr","text":"Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:43<00:00,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"INFO 03-24 21:08:05 [model_runner.py:1570] Graph capturing finished in 44 secs, took 0.21 GiB\nINFO 03-24 21:08:05 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 51.63 seconds\n","output_type":"stream"},{"name":"stderr","text":"\nProcessed prompts: 100%|██████████| 100/100 [00:34<00:00,  2.94it/s, est. speed input: 1277.11 toks/s, output: 2022.50 toks/s]\nProcessed prompts: 100%|██████████| 100/100 [00:33<00:00,  2.99it/s, est. speed input: 1298.22 toks/s, output: 2092.07 toks/s]\nRanking candidates: 100%|██████████| 50/50 [01:47<00:00,  2.14s/it]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def get_logprob(vllm_outputs):\n    logprobs = [output for output in vllm_outputs[0]]\n    logprobs = [[value for key, value in item.items()] for item in logprobs]\n    logprobs = [logprob[0].logprob for logprob in logprobs]\n    print(f\"len logprobs: {len(logprobs)}\")\n    return logprobs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:55:08.812917Z","iopub.execute_input":"2025-03-25T19:55:08.813112Z","iopub.status.idle":"2025-03-25T19:55:10.026534Z","shell.execute_reply.started":"2025-03-25T19:55:08.813095Z","shell.execute_reply":"2025-03-25T19:55:10.025409Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"get_logprob(only_outputs_rlhf_logprobs)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_logprob(only_outputs_sft_logprobs)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# rlhf_logprob = [output for output in only_outputs_rlhf_logprobs[0]]\n# rlhf_logprob\n# only_outputs_rlhf_logprobs[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T21:15:57.463752Z","iopub.execute_input":"2025-03-24T21:15:57.464073Z","iopub.status.idle":"2025-03-24T21:15:57.467599Z","shell.execute_reply.started":"2025-03-24T21:15:57.464051Z","shell.execute_reply":"2025-03-24T21:15:57.466675Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"rlhf_logprob = [output for output in only_outputs_rlhf_logprobs[0]]\nrlhf_logprob = [[value for key, value in item.items()] for item in rlhf_logprob]\nrlhf_logprob = [logprobs[0].logprob for logprobs in rlhf_logprob]\nrlhf_logprob = np.mean(rlhf_logprob)\nrlhf_logprob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T21:11:15.530683Z","iopub.execute_input":"2025-03-24T21:11:15.531667Z","iopub.status.idle":"2025-03-24T21:11:15.541359Z","shell.execute_reply.started":"2025-03-24T21:11:15.531635Z","shell.execute_reply":"2025-03-24T21:11:15.540520Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"-0.10280211417199071"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"sft_logprob = [output for output in only_outputs_sft_logprobs[0]]\nsft_logprob = [[value for key, value in item.items()] for item in sft_logprob]\nsft_logprob = [logprobs[0].logprob for logprobs in sft_logprob]\nsft_logprob = np.mean(sft_logprob)\nsft_logprob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T21:11:19.806049Z","iopub.execute_input":"2025-03-24T21:11:19.806402Z","iopub.status.idle":"2025-03-24T21:11:19.815152Z","shell.execute_reply.started":"2025-03-24T21:11:19.806374Z","shell.execute_reply":"2025-03-24T21:11:19.814257Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"-0.1221480804435428"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"kl = rlhf_logprob - sft_logprob\nkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T21:11:24.796659Z","iopub.execute_input":"2025-03-24T21:11:24.796961Z","iopub.status.idle":"2025-03-24T21:11:24.802375Z","shell.execute_reply.started":"2025-03-24T21:11:24.796939Z","shell.execute_reply":"2025-03-24T21:11:24.801465Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.019345966271552092"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"print(f\"model after dpo win rate: {comparison_results.sum() / comparison_results.shape[0]}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_win_rate_kl(model_path, sft_model, pair_rm):\n    sampling_params = SamplingParams(temperature=config.temperature, top_p=config.top_p,\n                                 max_tokens=config.max_tokens_output, \n                                 logprobs=20\n    )\n    comparison_results, outputs_rlhf, outputs_sft, only_outputs_rlhf_logprobs, only_outputs_sft_logprobs = give_text_answers(ds_eval, pair_rm, config.model_name, model_path, sampling_params)\n    model_logprobs = np.array(get_logprob(only_outputs_rlhf_logprobs))\n    sft_logprobs = np.array(get_logprob(only_outputs_sft_logprobs))\n    min_len = min(len(model_logprobs), len(sft_logprobs))\n    model_kl = np.mean(model_logprobs[-min_len:] - sft_logprobs[-min_len:])\n\n    win_rate = comparison_results.sum() / comparison_results.shape[0]\n    return {\"model_path\": model_path, \"win_rate\": win_rate, \"kl\": model_kl}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:55:10.027638Z","iopub.execute_input":"2025-03-25T19:55:10.028060Z","iopub.status.idle":"2025-03-25T19:55:11.032565Z","shell.execute_reply.started":"2025-03-25T19:55:10.028018Z","shell.execute_reply":"2025-03-25T19:55:11.031595Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# BEYOND REVERSE KL DIVERGANCE","metadata":{}},{"cell_type":"code","source":"class DPOForwardKL(DPOTrainer):\n    def __init__(self, model, processing_class, args, train_dataset, eval_dataset):\n        self.model = model\n        self.processing_class = processing_class\n        self.train_dataset = train_dataset\n        self.eval_dataset = eval_dataset\n        self.eps = 1e-5\n        super().__init__(model=model, processing_class=processing_class,\n                         args=args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n\n    def custom_func_derivative(self, x: float) -> torch.tensor:\n        # print(f\"arg: {x}\")\n        return -torch.pow(x + self.eps, -1)\n\n    def dpo_loss(\n        self,\n        chosen_logps: torch.FloatTensor,\n        rejected_logps: torch.FloatTensor,\n        ref_chosen_logps: torch.FloatTensor,\n        ref_rejected_logps: torch.FloatTensor,\n    ) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n        \"\"\"\n        Compute the DPO loss for a batch of policy and reference model log probabilities.\n\n        Args:\n                Log probabilities of the model for the chosen responses. Shape: `(batch_size,)`.\n            rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the model for the rejected responses. Shape: `(batch_size,)`.\n            ref_chosen_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the chosen responses. Shape: `(batch_size,)`.\n            ref_rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the rejected responses. Shape: `(batch_size,)`.\n\n        Returns:\n            A tuple of three tensors: `(losses, chosen_rewards, rejected_rewards)`.\n            The losses tensor contains the DPO loss for each example in the batch.\n            The `chosen_rewards` and `rejected_rewards` tensors contain the rewards for the chosen and rejected\n            responses, respectively.\n        \"\"\"\n        # print(f\"calc dpo loss\")\n        # print(f\"chosen_logps: {chosen_logps}\")\n        # print(f\"rejected_logps: {rejected_logps}\")\n        # print(f\"ref_chosen_logps: {ref_chosen_logps}\")\n        # print(f\"ref_rejected_logps: {ref_rejected_logps}\")\n        device = self.accelerator.device\n        chosen_logratios = chosen_logps.to(device) - (not self.reference_free) * ref_chosen_logps.to(device)\n        rejected_logratios = rejected_logps.to(device) - (not self.reference_free) * ref_rejected_logps.to(device)\n\n        # print(f\"chosen_logratios: {chosen_logratios}\")\n        # print(f\"rejected_logratios: {rejected_logratios}\")\n        if self.f_divergence_type == FDivergenceType.ALPHA_DIVERGENCE.value:\n            # The alpha-divergence formula: (1 - u^-alpha) / alpha\n            # The divergence difference between the chosen and rejected sample is:\n            #     (1 - u[w]^-alpha) / alpha - (1 - u[l]^-alpha) / alpha\n            #        = (u[l]^-alpha - u[w]^-alpha) / alpha\n            # where u[w] and u[l] are the policy/reference probability ratios\n            # for the chosen and rejected samples, respectively.\n            alpha_coef = FDivergenceConstants.ALPHA_DIVERGENCE_COEF_DEFAULT\n            if self.f_divergence_params and FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY in self.f_divergence_params:\n                alpha_coef = float(self.f_divergence_params[FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY])\n            logits = (cap_exp(rejected_logratios * -alpha_coef) - cap_exp(chosen_logratios * -alpha_coef)) / alpha_coef\n        else:\n            logratios = chosen_logps - rejected_logps\n            if self.reference_free:\n                ref_logratios = torch.tensor([0], dtype=logratios.dtype, device=logratios.device)\n            else:\n                ref_logratios = ref_chosen_logps - ref_rejected_logps\n\n            logratios = logratios.to(self.accelerator.device)\n            ref_logratios = ref_logratios.to(self.accelerator.device)\n            logits = logratios - ref_logratios\n\n            if self.f_divergence_type == FDivergenceType.JS_DIVERGENCE.value:\n                # The js-divergence formula: log(2 * u / (1 + u))\n                # The divergence difference between the chosen and rejected sample is:\n                #     log(2 * u[w] / (1 + u[w])) - log(2 * u[l] / (1 + u[l]))\n                #       = log(u[w]) - log(u[l]) - (log(1 + u[w]) - log(1 + u[l]))\n                # where u[w] and u[l] are the policy/reference probability ratios\n                # for the chosen and rejected samples, respectively.\n                logits -= F.softplus(chosen_logratios) - F.softplus(rejected_logratios)\n        losses = (- F.logsigmoid(self.beta * self.custom_func_derivative(chosen_logratios) - \\\n                    self.beta * self.custom_func_derivative(rejected_logratios)))\n        # print(f\"losses: {losses}\")\n        # print(f\"beta: {self.beta}\")\n        chosen_rewards = self.beta * (chosen_logps.to(device) - ref_chosen_logps.to(device)).detach()\n        rejected_rewards = self.beta * (rejected_logps.to(device) - ref_rejected_logps.to(device)).detach()\n        # print(f\"{losses}, {chosen_rewards}, {rejected_rewards}\")\n        return losses, chosen_rewards, rejected_rewards","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DPOReverseKL(DPOTrainer):\n    def __init__(self, model, processing_class, args, train_dataset, eval_dataset):\n        self.model = model\n        self.processing_class = processing_class\n        self.train_dataset = train_dataset\n        self.eval_dataset = eval_dataset\n        self.eps = 1e-5\n        super().__init__(model=model, processing_class=processing_class,\n                         args=args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n\n    def custom_func_derivative(self, x: torch.tensor) -> torch.tensor:\n        x = F.softplus(x)\n        return torch.log(x + self.eps) + 1\n\n    def dpo_loss(\n        self,\n        chosen_logps: torch.FloatTensor,\n        rejected_logps: torch.FloatTensor,\n        ref_chosen_logps: torch.FloatTensor,\n        ref_rejected_logps: torch.FloatTensor,\n    ) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n        \"\"\"\n        Compute the DPO loss for a batch of policy and reference model log probabilities.\n\n        Args:\n            chosen_logps (`torch.FloatTensor`):\n                Log probabilities of the model for the chosen responses. Shape: `(batch_size,)`.\n            rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the model for the rejected responses. Shape: `(batch_size,)`.\n            ref_chosen_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the chosen responses. Shape: `(batch_size,)`.\n            ref_rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the rejected responses. Shape: `(batch_size,)`.\n\n        Returns:\n            A tuple of three tensors: `(losses, chosen_rewards, rejected_rewards)`.\n            The losses tensor contains the DPO loss for each example in the batch.\n            The `chosen_rewards` and `rejected_rewards` tensors contain the rewards for the chosen and rejected\n            responses, respectively.\n        \"\"\"\n        # print(f\"calc dpo loss\")\n        device = self.accelerator.device\n        # print(f\"chosen_logps: {chosen_logps}, ref_chosen_logps: {ref_chosen_logps}\")\n        # print(f\"rejected_logps: {rejected_logps}, ref_rejected_logps: {ref_rejected_logps}\")\n        chosen_logratios = chosen_logps.to(device) - (not self.reference_free) * ref_chosen_logps.to(device)\n        rejected_logratios = rejected_logps.to(device) - (not self.reference_free) * ref_rejected_logps.to(device)\n\n        # print(f\"chosen_logratios: {chosen_logratios}\")\n        # print(f\"rejected_logratios: {rejected_logratios}\")\n        if self.f_divergence_type == FDivergenceType.ALPHA_DIVERGENCE.value:\n            # The alpha-divergence formula: (1 - u^-alpha) / alpha\n            # The divergence difference between the chosen and rejected sample is:\n            #     (1 - u[w]^-alpha) / alpha - (1 - u[l]^-alpha) / alpha\n            #        = (u[l]^-alpha - u[w]^-alpha) / alpha\n            # where u[w] and u[l] are the policy/reference probability ratios\n            # for the chosen and rejected samples, respectively.\n            alpha_coef = FDivergenceConstants.ALPHA_DIVERGENCE_COEF_DEFAULT\n            if self.f_divergence_params and FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY in self.f_divergence_params:\n                alpha_coef = float(self.f_divergence_params[FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY])\n            logits = (cap_exp(rejected_logratios * -alpha_coef) - cap_exp(chosen_logratios * -alpha_coef)) / alpha_coef\n        else:\n            logratios = chosen_logps - rejected_logps\n            if self.reference_free:\n                ref_logratios = torch.tensor([0], dtype=logratios.dtype, device=logratios.device)\n            else:\n                ref_logratios = ref_chosen_logps - ref_rejected_logps\n\n            logratios = logratios.to(self.accelerator.device)\n            ref_logratios = ref_logratios.to(self.accelerator.device)\n            logits = logratios - ref_logratios\n\n            if self.f_divergence_type == FDivergenceType.JS_DIVERGENCE.value:\n                # The js-divergence formula: log(2 * u / (1 + u))\n                # The divergence difference between the chosen and rejected sample is:\n                #     log(2 * u[w] / (1 + u[w])) - log(2 * u[l] / (1 + u[l]))\n                #       = log(u[w]) - log(u[l]) - (log(1 + u[w]) - log(1 + u[l]))\n                # where u[w] and u[l] are the policy/reference probability ratios\n                # for the chosen and rejected samples, respectively.\n                logits -= F.softplus(chosen_logratios) - F.softplus(rejected_logratios)\n        losses = (- F.logsigmoid(self.beta * self.custom_func_derivative(chosen_logratios) - \\\n                    self.beta * self.custom_func_derivative(rejected_logratios)))\n        # print(f\"losses: {losses}\")\n\n        chosen_rewards = self.beta * (chosen_logps.to(device) - ref_chosen_logps.to(device)).detach()\n        rejected_rewards = self.beta * (rejected_logps.to(device) - ref_rejected_logps.to(device)).detach()\n        # print(f\"{chosen_rewards}, {rejected_rewards}\")\n        return losses, chosen_rewards, rejected_rewards","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T18:48:38.714408Z","iopub.execute_input":"2025-03-16T18:48:38.714721Z","iopub.status.idle":"2025-03-16T18:48:38.725978Z","shell.execute_reply.started":"2025-03-16T18:48:38.714697Z","shell.execute_reply":"2025-03-16T18:48:38.725153Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"@dataclass\nclass Config:\n  seed: int = 42\n  dataset_path: str = 'HuggingFaceH4/ultrafeedback_binarized'\n  model_name: str = 'HuggingFaceTB/SmolLM-135M-Instruct'\n\n  pair_rm_model: str = \"llm-blender/PairRM\"\n  eval_size: int = 100\n\n  temperature: float = 0.2\n  top_p: float = 0.95\n\n\n  max_seq_len: int = 1024\n\n  output_dir: str = \"/kaggle/working/trained_dpo_forward_kl\"\n  eval_steps: int = 10\n  gradient_accumulation_steps: int = 4\n  gradient_checkpointing: bool = True\n  batch_size: int = 4\n  max_prompt_length: int = 128\n  max_completion_length: int = 256\n  max_steps: int = 200\n  lr_scheduler_type: str = \"cosine\" \n  learning_rate: int = 5e-5\n  logging_steps: int = 10\n  bf16: bool = True # try on P100\n  fp16: bool = False\n  tf32: bool = False\n  beta: float = 0.1\n\n  max_tokens_output: int = 768\n\n  def __post_init__(self):\n    self.num_proc = os.cpu_count() // torch.cuda.device_count() if torch.cuda.is_available() else 1\n    self.model_rlhf = \"/kaggle/input/trained-dpo-a-5e-5/kaggle/working/trained_dpo\"\n\nforward_kl_config = Config()\nforward_kl_config.beta = 0.1\n# print(config.num_proc)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = DPOConfig(\n    output_dir=forward_kl_config.output_dir,\n    eval_strategy=\"steps\",\n    eval_steps=forward_kl_config.eval_steps,\n    report_to=\"wandb\",\n    # report_to=\"none\",\n    gradient_accumulation_steps=forward_kl_config.gradient_accumulation_steps,\n    gradient_checkpointing=forward_kl_config.gradient_checkpointing,\n    per_device_train_batch_size=forward_kl_config.batch_size,\n    per_device_eval_batch_size=forward_kl_config.batch_size,\n    max_prompt_length=forward_kl_config.max_prompt_length,\n    max_completion_length=forward_kl_config.max_completion_length,\n    max_steps=forward_kl_config.max_steps,\n    lr_scheduler_type=forward_kl_config.lr_scheduler_type,\n    learning_rate=forward_kl_config.learning_rate,\n    logging_steps=forward_kl_config.logging_steps,\n    beta=forward_kl_config.beta,\n    fp16=forward_kl_config.fp16,\n    tf32=forward_kl_config.tf32,\n    bf16=forward_kl_config.bf16,\n    loss_type=\"forward_kl\"\n)\nforward_dpo_trainer = DPOForwardKL(\n    model=model,\n    processing_class=tokenizer,\n    args=training_args,\n    train_dataset=ds[\"train_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"]),\n    eval_dataset=ds[\"test_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"])\n)\nforward_dpo_trainer.train()\nforward_dpo_trainer.save_model()","metadata":{"id":"7NwR94DzhG-E","trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/trained_dpo_forward_kl.zip /kaggle/working/trained_dpo_forward_kl","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os \nfrom IPython.display import FileLink\n\n\nos.chdir(r'/kaggle/working')\nFileLink(r'trained_dpo_forward_kl.zip')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T15:50:32.064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reverse_kl_config = Config()\nreverse_kl_config.beta = 0.1\nreverse_kl_config.output_dir = \"/kaggle/working/trained_dpo_reverse_kl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T18:47:33.325136Z","iopub.execute_input":"2025-03-16T18:47:33.325358Z","iopub.status.idle":"2025-03-16T18:47:33.330244Z","shell.execute_reply.started":"2025-03-16T18:47:33.325338Z","shell.execute_reply":"2025-03-16T18:47:33.329455Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"training_args = DPOConfig(\n    output_dir=reverse_kl_config.output_dir,\n    eval_strategy=\"steps\",\n    eval_steps=reverse_kl_config.eval_steps,\n    report_to=\"wandb\",\n    # report_to=\"none\",\n    gradient_accumulation_steps=reverse_kl_config.gradient_accumulation_steps,\n    gradient_checkpointing=reverse_kl_config.gradient_checkpointing,\n    per_device_train_batch_size=reverse_kl_config.batch_size,\n    per_device_eval_batch_size=reverse_kl_config.batch_size,\n    max_prompt_length=reverse_kl_config.max_prompt_length,\n    max_completion_length=reverse_kl_config.max_completion_length,\n    max_steps=reverse_kl_config.max_steps,\n    lr_scheduler_type=reverse_kl_config.lr_scheduler_type,\n    learning_rate=reverse_kl_config.learning_rate,\n    logging_steps=reverse_kl_config.logging_steps,\n    beta=reverse_kl_config.beta,\n    fp16=reverse_kl_config.fp16,\n    tf32=reverse_kl_config.tf32,\n    bf16=reverse_kl_config.bf16,\n    loss_type=\"reverse_kl\"\n)\nreverse_dpo_trainer = DPOReverseKL(\n    model=model,\n    processing_class=tokenizer,\n    args=training_args,\n    train_dataset=ds[\"train_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"]),\n    eval_dataset=ds[\"test_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"])\n)\nreverse_dpo_trainer.train()\nreverse_dpo_trainer.save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T18:48:44.363430Z","iopub.execute_input":"2025-03-16T18:48:44.363798Z","iopub.status.idle":"2025-03-16T19:39:17.334586Z","shell.execute_reply.started":"2025-03-16T18:48:44.363749Z","shell.execute_reply":"2025-03-16T19:39:17.333852Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Extracting prompt in train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbf53d2b8a994a998503f0eb5dc0938e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cc3fa0bc0b340b293b1f48c2ae6a8ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c901127e395406d9e28b27b8b88cab4"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting prompt in eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8e2a32e72794c929efe5420bf62348a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfd0f2f09e4743c79a297c4ac6074d62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b6355cd1d42466e80635920da3b5ab9"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 50:20, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/chosen</th>\n      <th>Logps/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Logits/rejected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.684800</td>\n      <td>0.687834</td>\n      <td>-0.068932</td>\n      <td>-0.085605</td>\n      <td>0.542918</td>\n      <td>0.016672</td>\n      <td>-295.854340</td>\n      <td>-289.809326</td>\n      <td>-0.536630</td>\n      <td>-0.369855</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.688900</td>\n      <td>0.683202</td>\n      <td>-0.087601</td>\n      <td>-0.117411</td>\n      <td>0.557940</td>\n      <td>0.029810</td>\n      <td>-296.041046</td>\n      <td>-290.127380</td>\n      <td>-0.530776</td>\n      <td>-0.364754</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.678100</td>\n      <td>0.679506</td>\n      <td>-0.092928</td>\n      <td>-0.133583</td>\n      <td>0.567597</td>\n      <td>0.040655</td>\n      <td>-296.094330</td>\n      <td>-290.289093</td>\n      <td>-0.521573</td>\n      <td>-0.355945</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.674900</td>\n      <td>0.677640</td>\n      <td>-0.104654</td>\n      <td>-0.151251</td>\n      <td>0.583691</td>\n      <td>0.046597</td>\n      <td>-296.211578</td>\n      <td>-290.465759</td>\n      <td>-0.516229</td>\n      <td>-0.351464</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.685500</td>\n      <td>0.676777</td>\n      <td>-0.110211</td>\n      <td>-0.160270</td>\n      <td>0.584764</td>\n      <td>0.050059</td>\n      <td>-296.267120</td>\n      <td>-290.555969</td>\n      <td>-0.517217</td>\n      <td>-0.352834</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.622300</td>\n      <td>0.677001</td>\n      <td>-0.133105</td>\n      <td>-0.184919</td>\n      <td>0.571888</td>\n      <td>0.051815</td>\n      <td>-296.496063</td>\n      <td>-290.802460</td>\n      <td>-0.534291</td>\n      <td>-0.370242</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.604300</td>\n      <td>0.674172</td>\n      <td>-0.160841</td>\n      <td>-0.221464</td>\n      <td>0.586910</td>\n      <td>0.060622</td>\n      <td>-296.773438</td>\n      <td>-291.167908</td>\n      <td>-0.543769</td>\n      <td>-0.379036</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.591500</td>\n      <td>0.673954</td>\n      <td>-0.185953</td>\n      <td>-0.249024</td>\n      <td>0.565451</td>\n      <td>0.063071</td>\n      <td>-297.024567</td>\n      <td>-291.443512</td>\n      <td>-0.560539</td>\n      <td>-0.396896</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.588000</td>\n      <td>0.672208</td>\n      <td>-0.204645</td>\n      <td>-0.273968</td>\n      <td>0.576180</td>\n      <td>0.069324</td>\n      <td>-297.211487</td>\n      <td>-291.692963</td>\n      <td>-0.566233</td>\n      <td>-0.402573</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.587600</td>\n      <td>0.671099</td>\n      <td>-0.215355</td>\n      <td>-0.287397</td>\n      <td>0.587983</td>\n      <td>0.072041</td>\n      <td>-297.318604</td>\n      <td>-291.827209</td>\n      <td>-0.572336</td>\n      <td>-0.408166</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.592100</td>\n      <td>0.672309</td>\n      <td>-0.223974</td>\n      <td>-0.293330</td>\n      <td>0.569743</td>\n      <td>0.069356</td>\n      <td>-297.404785</td>\n      <td>-291.886597</td>\n      <td>-0.583597</td>\n      <td>-0.418463</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.577000</td>\n      <td>0.670978</td>\n      <td>-0.226157</td>\n      <td>-0.298668</td>\n      <td>0.590129</td>\n      <td>0.072511</td>\n      <td>-297.426605</td>\n      <td>-291.939972</td>\n      <td>-0.583123</td>\n      <td>-0.418818</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.589500</td>\n      <td>0.670245</td>\n      <td>-0.225569</td>\n      <td>-0.300654</td>\n      <td>0.589056</td>\n      <td>0.075085</td>\n      <td>-297.420715</td>\n      <td>-291.959808</td>\n      <td>-0.582539</td>\n      <td>-0.418554</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.570400</td>\n      <td>0.669042</td>\n      <td>-0.227155</td>\n      <td>-0.305280</td>\n      <td>0.579399</td>\n      <td>0.078124</td>\n      <td>-297.436554</td>\n      <td>-292.006073</td>\n      <td>-0.586863</td>\n      <td>-0.421913</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.572600</td>\n      <td>0.670907</td>\n      <td>-0.229454</td>\n      <td>-0.302578</td>\n      <td>0.580472</td>\n      <td>0.073124</td>\n      <td>-297.459564</td>\n      <td>-291.979034</td>\n      <td>-0.584655</td>\n      <td>-0.419953</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.548100</td>\n      <td>0.670896</td>\n      <td>-0.229790</td>\n      <td>-0.303884</td>\n      <td>0.586910</td>\n      <td>0.074094</td>\n      <td>-297.462921</td>\n      <td>-291.992096</td>\n      <td>-0.584267</td>\n      <td>-0.419336</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.572700</td>\n      <td>0.672302</td>\n      <td>-0.229262</td>\n      <td>-0.299923</td>\n      <td>0.567597</td>\n      <td>0.070661</td>\n      <td>-297.457611</td>\n      <td>-291.952484</td>\n      <td>-0.584780</td>\n      <td>-0.420240</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.542300</td>\n      <td>0.670195</td>\n      <td>-0.229097</td>\n      <td>-0.303571</td>\n      <td>0.594421</td>\n      <td>0.074474</td>\n      <td>-297.455994</td>\n      <td>-291.989014</td>\n      <td>-0.582685</td>\n      <td>-0.417618</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.581300</td>\n      <td>0.672145</td>\n      <td>-0.231411</td>\n      <td>-0.301266</td>\n      <td>0.571888</td>\n      <td>0.069855</td>\n      <td>-297.479156</td>\n      <td>-291.965912</td>\n      <td>-0.582462</td>\n      <td>-0.418583</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.559700</td>\n      <td>0.672677</td>\n      <td>-0.232638</td>\n      <td>-0.301978</td>\n      <td>0.579399</td>\n      <td>0.069340</td>\n      <td>-297.491425</td>\n      <td>-291.973083</td>\n      <td>-0.583006</td>\n      <td>-0.418491</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"!zip -r /kaggle/working/trained_dpo_reverse_kl.zip /kaggle/working/trained_dpo_reverse_kl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T19:41:46.912825Z","iopub.execute_input":"2025-03-16T19:41:46.913179Z","iopub.status.idle":"2025-03-16T19:43:45.085786Z","shell.execute_reply.started":"2025-03-16T19:41:46.913150Z","shell.execute_reply":"2025-03-16T19:43:45.084712Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/trained_dpo_reverse_kl/ (stored 0%)\n  adding: kaggle/working/trained_dpo_reverse_kl/merges.txt (deflated 55%)\n  adding: kaggle/working/trained_dpo_reverse_kl/tokenizer.json (deflated 82%)\n  adding: kaggle/working/trained_dpo_reverse_kl/generation_config.json (deflated 30%)\n  adding: kaggle/working/trained_dpo_reverse_kl/config.json (deflated 46%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/ (stored 0%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/rng_state.pth (deflated 25%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/merges.txt (deflated 55%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/trainer_state.json (deflated 78%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/tokenizer.json (deflated 82%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/generation_config.json (deflated 30%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/config.json (deflated 46%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/scheduler.pt (deflated 56%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/training_args.bin (deflated 52%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/tokenizer_config.json (deflated 85%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/model.safetensors (deflated 21%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/special_tokens_map.json (deflated 71%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/vocab.json (deflated 59%)\n  adding: kaggle/working/trained_dpo_reverse_kl/checkpoint-200/optimizer.pt (deflated 24%)\n  adding: kaggle/working/trained_dpo_reverse_kl/training_args.bin (deflated 52%)\n  adding: kaggle/working/trained_dpo_reverse_kl/tokenizer_config.json (deflated 85%)\n  adding: kaggle/working/trained_dpo_reverse_kl/model.safetensors (deflated 21%)\n  adding: kaggle/working/trained_dpo_reverse_kl/special_tokens_map.json (deflated 71%)\n  adding: kaggle/working/trained_dpo_reverse_kl/vocab.json (deflated 59%)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os \nfrom IPython.display import FileLink\n\n\nos.chdir(r'/kaggle/working')\nFileLink(r'trained_dpo_reverse_kl.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T19:43:45.087286Z","iopub.execute_input":"2025-03-16T19:43:45.087551Z","iopub.status.idle":"2025-03-16T19:43:45.094468Z","shell.execute_reply.started":"2025-03-16T19:43:45.087527Z","shell.execute_reply":"2025-03-16T19:43:45.093834Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/trained_dpo_reverse_kl.zip","text/html":"<a href='trained_dpo_reverse_kl.zip' target='_blank'>trained_dpo_reverse_kl.zip</a><br>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AlphaDivergence(DPOTrainer):\n    def __init__(self, model, processing_class, args, train_dataset, eval_dataset):\n        self.model = model\n        self.processing_class = processing_class\n        self.train_dataset = train_dataset\n        self.eval_dataset = eval_dataset\n        self.eps = 1e-5\n        self.alpha = 0.5\n        super().__init__(model=model, processing_class=processing_class,\n                         args=args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n\n    def custom_func_derivative(self, x: float) -> torch.tensor:\n        # pow with 0 < rate < 1 => x > 0 - domain\n        x = F.softplus(x)\n        return (1 - torch.pow(x + self.eps, -self.alpha)) / self.alpha\n\n    def dpo_loss(\n        self,\n        chosen_logps: torch.FloatTensor,\n        rejected_logps: torch.FloatTensor,\n        ref_chosen_logps: torch.FloatTensor,\n        ref_rejected_logps: torch.FloatTensor,\n    ) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n        \"\"\"\n        Compute the DPO loss for a batch of policy and reference model log probabilities.\n\n        Args:\n            chosen_logps (`torch.FloatTensor`):\n                Log probabilities of the model for the chosen responses. Shape: `(batch_size,)`.\n            rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the model for the rejected responses. Shape: `(batch_size,)`.\n            ref_chosen_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the chosen responses. Shape: `(batch_size,)`.\n            ref_rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the rejected responses. Shape: `(batch_size,)`.\n\n        Returns:\n            A tuple of three tensors: `(losses, chosen_rewards, rejected_rewards)`.\n            The losses tensor contains the DPO loss for each example in the batch.\n            The `chosen_rewards` and `rejected_rewards` tensors contain the rewards for the chosen and rejected\n            responses, respectively.\n        \"\"\"\n        device = self.accelerator.device\n        chosen_logratios = chosen_logps.to(device) - (not self.reference_free) * ref_chosen_logps.to(device)\n        rejected_logratios = rejected_logps.to(device) - (not self.reference_free) * ref_rejected_logps.to(device)\n\n        if self.f_divergence_type == FDivergenceType.ALPHA_DIVERGENCE.value:\n            # The alpha-divergence formula: (1 - u^-alpha) / alpha\n            # The divergence difference between the chosen and rejected sample is:\n            #     (1 - u[w]^-alpha) / alpha - (1 - u[l]^-alpha) / alpha\n            #        = (u[l]^-alpha - u[w]^-alpha) / alpha\n            # where u[w] and u[l] are the policy/reference probability ratios\n            # for the chosen and rejected samples, respectively.\n            alpha_coef = FDivergenceConstants.ALPHA_DIVERGENCE_COEF_DEFAULT\n            if self.f_divergence_params and FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY in self.f_divergence_params:\n                alpha_coef = float(self.f_divergence_params[FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY])\n            logits = (cap_exp(rejected_logratios * -alpha_coef) - cap_exp(chosen_logratios * -alpha_coef)) / alpha_coef\n        else:\n            logratios = chosen_logps - rejected_logps\n            if self.reference_free:\n                ref_logratios = torch.tensor([0], dtype=logratios.dtype, device=logratios.device)\n            else:\n                ref_logratios = ref_chosen_logps - ref_rejected_logps\n\n            logratios = logratios.to(self.accelerator.device)\n            ref_logratios = ref_logratios.to(self.accelerator.device)\n            logits = logratios - ref_logratios\n\n            if self.f_divergence_type == FDivergenceType.JS_DIVERGENCE.value:\n                # The js-divergence formula: log(2 * u / (1 + u))\n                # The divergence difference between the chosen and rejected sample is:\n                #     log(2 * u[w] / (1 + u[w])) - log(2 * u[l] / (1 + u[l]))\n                #       = log(u[w]) - log(u[l]) - (log(1 + u[w]) - log(1 + u[l]))\n                # where u[w] and u[l] are the policy/reference probability ratios\n                # for the chosen and rejected samples, respectively.\n                logits -= F.softplus(chosen_logratios) - F.softplus(rejected_logratios)\n        losses = (- F.logsigmoid(self.beta * self.custom_func_derivative(chosen_logratios) - \\\n                    self.beta * self.custom_func_derivative(rejected_logratios)))\n\n        chosen_rewards = self.beta * (chosen_logps.to(device) - ref_chosen_logps.to(device)).detach()\n        rejected_rewards = self.beta * (rejected_logps.to(device) - ref_rejected_logps.to(device)).detach()\n        return losses, chosen_rewards, rejected_rewards","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:08:04.043978Z","iopub.execute_input":"2025-03-16T16:08:04.044240Z","iopub.status.idle":"2025-03-16T16:08:04.055650Z","shell.execute_reply.started":"2025-03-16T16:08:04.044218Z","shell.execute_reply":"2025-03-16T16:08:04.054985Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class JSDivergence(DPOTrainer):\n    def __init__(self, model, processing_class, args, train_dataset, eval_dataset):\n        self.model = model\n        self.processing_class = processing_class\n        self.train_dataset = train_dataset\n        self.eval_dataset = eval_dataset\n        self.eps = 1e-5\n        super().__init__(model=model, processing_class=processing_class,\n                         args=args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n\n    def custom_func_derivative(self, x: float) -> torch.tensor:\n        # print(f\"arg: {x}\")\n        # log: domain > 0\n        x = F.softplus(2 * x / (1 + x))\n        return torch.log(x + self.eps)\n\n    def dpo_loss(\n        self,\n        chosen_logps: torch.FloatTensor,\n        rejected_logps: torch.FloatTensor,\n        ref_chosen_logps: torch.FloatTensor,\n        ref_rejected_logps: torch.FloatTensor,\n    ) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n        \"\"\"\n        Compute the DPO loss for a batch of policy and reference model log probabilities.\n\n        Args:\n            chosen_logps (`torch.FloatTensor`):\n                Log probabilities of the model for the chosen responses. Shape: `(batch_size,)`.\n            rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the model for the rejected responses. Shape: `(batch_size,)`.\n            ref_chosen_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the chosen responses. Shape: `(batch_size,)`.\n            ref_rejected_logps (`torch.FloatTensor`):\n                Log probabilities of the reference model for the rejected responses. Shape: `(batch_size,)`.\n\n        Returns:\n            A tuple of three tensors: `(losses, chosen_rewards, rejected_rewards)`.\n            The losses tensor contains the DPO loss for each example in the batch.\n            The `chosen_rewards` and `rejected_rewards` tensors contain the rewards for the chosen and rejected\n            responses, respectively.\n        \"\"\"\n        # print(f\"calc dpo loss\")\n        device = self.accelerator.device\n        # print(f\"device: {device}\")\n        chosen_logratios = chosen_logps.to(device) - (not self.reference_free) * ref_chosen_logps.to(device)\n        rejected_logratios = rejected_logps.to(device) - (not self.reference_free) * ref_rejected_logps.to(device)\n\n        # print(f\"chosen_logratios: {chosen_logratios}\")\n        # print(f\"rejected_logratios: {rejected_logratios}\")\n        if self.f_divergence_type == FDivergenceType.ALPHA_DIVERGENCE.value:\n            # The alpha-divergence formula: (1 - u^-alpha) / alpha\n            # The divergence difference between the chosen and rejected sample is:\n            #     (1 - u[w]^-alpha) / alpha - (1 - u[l]^-alpha) / alpha\n            #        = (u[l]^-alpha - u[w]^-alpha) / alpha\n            # where u[w] and u[l] are the policy/reference probability ratios\n            # for the chosen and rejected samples, respectively.\n            alpha_coef = FDivergenceConstants.ALPHA_DIVERGENCE_COEF_DEFAULT\n            if self.f_divergence_params and FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY in self.f_divergence_params:\n                alpha_coef = float(self.f_divergence_params[FDivergenceConstants.ALPHA_DIVERGENCE_COEF_KEY])\n            logits = (cap_exp(rejected_logratios * -alpha_coef) - cap_exp(chosen_logratios * -alpha_coef)) / alpha_coef\n        else:\n            logratios = chosen_logps - rejected_logps\n            if self.reference_free:\n                ref_logratios = torch.tensor([0], dtype=logratios.dtype, device=logratios.device)\n            else:\n                ref_logratios = ref_chosen_logps - ref_rejected_logps\n\n            logratios = logratios.to(self.accelerator.device)\n            ref_logratios = ref_logratios.to(self.accelerator.device)\n            logits = logratios - ref_logratios\n\n            if self.f_divergence_type == FDivergenceType.JS_DIVERGENCE.value:\n                # The js-divergence formula: log(2 * u / (1 + u))\n                # The divergence difference between the chosen and rejected sample is:\n                #     log(2 * u[w] / (1 + u[w])) - log(2 * u[l] / (1 + u[l]))\n                #       = log(u[w]) - log(u[l]) - (log(1 + u[w]) - log(1 + u[l]))\n                # where u[w] and u[l] are the policy/reference probability ratios\n                # for the chosen and rejected samples, respectively.\n                logits -= F.softplus(chosen_logratios) - F.softplus(rejected_logratios)\n        losses = (- F.logsigmoid(self.beta * self.custom_func_derivative(chosen_logratios) - \\\n                    self.beta * self.custom_func_derivative(rejected_logratios)))\n        # print(f\"losses: {losses}\")\n\n        chosen_rewards = self.beta * (chosen_logps.to(device) - ref_chosen_logps.to(device)).detach()\n        rejected_rewards = self.beta * (rejected_logps.to(device) - ref_rejected_logps.to(device)).detach()\n        # print(f\"{chosen_rewards}, {rejected_rewards}\")\n        return losses, chosen_rewards, rejected_rewards","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T19:46:13.057922Z","iopub.execute_input":"2025-03-16T19:46:13.058214Z","iopub.status.idle":"2025-03-16T19:46:13.069259Z","shell.execute_reply.started":"2025-03-16T19:46:13.058191Z","shell.execute_reply":"2025-03-16T19:46:13.068447Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"alpha_kl_config = Config()\nalpha_kl_config.beta = 0.1\nalpha_kl_config.output_dir = \"/kaggle/working/trained_dpo_alpha_kl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:08:04.057367Z","iopub.execute_input":"2025-03-16T16:08:04.057600Z","iopub.status.idle":"2025-03-16T16:08:04.079879Z","shell.execute_reply.started":"2025-03-16T16:08:04.057579Z","shell.execute_reply":"2025-03-16T16:08:04.079149Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"training_args = DPOConfig(\n    output_dir=alpha_kl_config.output_dir,\n    eval_strategy=\"steps\",\n    eval_steps=alpha_kl_config.eval_steps,\n    report_to=\"wandb\",\n    # report_to=\"none\",\n    gradient_accumulation_steps=alpha_kl_config.gradient_accumulation_steps,\n    gradient_checkpointing=alpha_kl_config.gradient_checkpointing,\n    per_device_train_batch_size=alpha_kl_config.batch_size,\n    per_device_eval_batch_size=alpha_kl_config.batch_size,\n    max_prompt_length=alpha_kl_config.max_prompt_length,\n    max_completion_length=alpha_kl_config.max_completion_length,\n    max_steps=alpha_kl_config.max_steps,\n    lr_scheduler_type=alpha_kl_config.lr_scheduler_type,\n    learning_rate=alpha_kl_config.learning_rate,\n    logging_steps=alpha_kl_config.logging_steps,\n    beta=alpha_kl_config.beta,\n    fp16=alpha_kl_config.fp16,\n    tf32=alpha_kl_config.tf32,\n    bf16=alpha_kl_config.bf16,\n    loss_type=\"alpha_kl\"\n)\nalpha_dpo_trainer = AlphaDivergence(\n    model=model,\n    processing_class=tokenizer,\n    args=training_args,\n    train_dataset=ds[\"train_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"]),\n    eval_dataset=ds[\"test_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"])\n)\nalpha_dpo_trainer.train()\nalpha_dpo_trainer.save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:08:36.071551Z","iopub.execute_input":"2025-03-16T16:08:36.071912Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Extracting prompt in train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9303a0cf944852b217a5b9a26c2e29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe622a08d1647c5b4e3aa28b39ab623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0683d946bc4a4c54bc281d65ef00dd6a"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting prompt in eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcf6e661917942d89edf674a784db1f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79de663384e04178968bf29adad35aec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"497e70508f464b87bab7b53bb400dcd9"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='21' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 21/200 03:08 < 29:39, 0.10 it/s, Epoch 0.34/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/chosen</th>\n      <th>Logps/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Logits/rejected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.686100</td>\n      <td>0.686631</td>\n      <td>-0.071496</td>\n      <td>-0.089563</td>\n      <td>0.534335</td>\n      <td>0.018067</td>\n      <td>-295.880005</td>\n      <td>-289.848907</td>\n      <td>-0.538522</td>\n      <td>-0.371807</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='88' max='233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 88/233 00:40 < 01:08, 2.13 it/s]\n    </div>\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/trained_dpo_alpha_kl.zip /kaggle/working/trained_dpo_alpha_kl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os \nfrom IPython.display import FileLink\n\n\nos.chdir(r'/kaggle/working')\nFileLink(r'trained_dpo_alpha_kl.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"js_kl_config = Config()\njs_kl_config.beta = 0.1\njs_kl_config.output_dir = \"/kaggle/working/trained_dpo_js_kl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T19:46:09.110968Z","iopub.execute_input":"2025-03-16T19:46:09.111312Z","iopub.status.idle":"2025-03-16T19:46:09.116397Z","shell.execute_reply.started":"2025-03-16T19:46:09.111282Z","shell.execute_reply":"2025-03-16T19:46:09.115577Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"training_args = DPOConfig(\n    output_dir=js_kl_config.output_dir,\n    eval_strategy=\"steps\",\n    eval_steps=js_kl_config.eval_steps,\n    report_to=\"wandb\",\n    # report_to=\"none\",\n    gradient_accumulation_steps=js_kl_config.gradient_accumulation_steps,\n    gradient_checkpointing=js_kl_config.gradient_checkpointing,\n    per_device_train_batch_size=js_kl_config.batch_size,\n    per_device_eval_batch_size=js_kl_config.batch_size,\n    max_prompt_length=js_kl_config.max_prompt_length,\n    max_completion_length=js_kl_config.max_completion_length,\n    max_steps=js_kl_config.max_steps,\n    lr_scheduler_type=js_kl_config.lr_scheduler_type,\n    learning_rate=js_kl_config.learning_rate,\n    logging_steps=js_kl_config.logging_steps,\n    beta=js_kl_config.beta,\n    fp16=js_kl_config.fp16,\n    tf32=js_kl_config.tf32,\n    bf16=js_kl_config.bf16,\n    loss_type=\"js_kl\"\n)\njs_dpo_trainer = JSDivergence(\n    model=model,\n    processing_class=tokenizer,\n    args=training_args,\n    train_dataset=ds[\"train_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"]),\n    eval_dataset=ds[\"test_prefs\"].select_columns([\"prompt\", \"chosen\", \"rejected\"])\n)\njs_dpo_trainer.train()\njs_dpo_trainer.save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T19:47:17.819447Z","iopub.execute_input":"2025-03-16T19:47:17.819802Z","iopub.status.idle":"2025-03-16T20:37:50.533842Z","shell.execute_reply.started":"2025-03-16T19:47:17.819771Z","shell.execute_reply":"2025-03-16T20:37:50.533126Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bc29e8d25a64992ba264648d2a0e8a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6519dedd1c64ff3a6bb047ddb103229"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 50:24, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/chosen</th>\n      <th>Logps/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Logits/rejected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.714100</td>\n      <td>0.735056</td>\n      <td>-0.097483</td>\n      <td>-0.115338</td>\n      <td>0.533262</td>\n      <td>0.017855</td>\n      <td>-296.139862</td>\n      <td>-290.106659</td>\n      <td>-0.559159</td>\n      <td>-0.392593</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.725300</td>\n      <td>0.719982</td>\n      <td>-0.111158</td>\n      <td>-0.130998</td>\n      <td>0.536481</td>\n      <td>0.019840</td>\n      <td>-296.276581</td>\n      <td>-290.263245</td>\n      <td>-0.568547</td>\n      <td>-0.402633</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.734400</td>\n      <td>0.726930</td>\n      <td>-0.087303</td>\n      <td>-0.107320</td>\n      <td>0.541846</td>\n      <td>0.020018</td>\n      <td>-296.038055</td>\n      <td>-290.026489</td>\n      <td>-0.557687</td>\n      <td>-0.392267</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.710400</td>\n      <td>0.715051</td>\n      <td>-0.074721</td>\n      <td>-0.095524</td>\n      <td>0.543991</td>\n      <td>0.020803</td>\n      <td>-295.912262</td>\n      <td>-289.908508</td>\n      <td>-0.546171</td>\n      <td>-0.380089</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.702200</td>\n      <td>0.724574</td>\n      <td>-0.057147</td>\n      <td>-0.086139</td>\n      <td>0.571888</td>\n      <td>0.028992</td>\n      <td>-295.736481</td>\n      <td>-289.814667</td>\n      <td>-0.530055</td>\n      <td>-0.364650</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.666000</td>\n      <td>0.730312</td>\n      <td>-0.057353</td>\n      <td>-0.086081</td>\n      <td>0.578326</td>\n      <td>0.028728</td>\n      <td>-295.738525</td>\n      <td>-289.814087</td>\n      <td>-0.526059</td>\n      <td>-0.360249</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.718400</td>\n      <td>0.719466</td>\n      <td>-0.061785</td>\n      <td>-0.088576</td>\n      <td>0.552575</td>\n      <td>0.026792</td>\n      <td>-295.782898</td>\n      <td>-289.839020</td>\n      <td>-0.523502</td>\n      <td>-0.358059</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.724800</td>\n      <td>0.726447</td>\n      <td>-0.051547</td>\n      <td>-0.082127</td>\n      <td>0.567597</td>\n      <td>0.030580</td>\n      <td>-295.680511</td>\n      <td>-289.774536</td>\n      <td>-0.519247</td>\n      <td>-0.353434</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.723800</td>\n      <td>0.722084</td>\n      <td>-0.047250</td>\n      <td>-0.073177</td>\n      <td>0.560086</td>\n      <td>0.025927</td>\n      <td>-295.637543</td>\n      <td>-289.685059</td>\n      <td>-0.515074</td>\n      <td>-0.349967</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.709300</td>\n      <td>0.716559</td>\n      <td>-0.045040</td>\n      <td>-0.071376</td>\n      <td>0.577253</td>\n      <td>0.026337</td>\n      <td>-295.615417</td>\n      <td>-289.667053</td>\n      <td>-0.513197</td>\n      <td>-0.347867</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.688200</td>\n      <td>0.716038</td>\n      <td>-0.047040</td>\n      <td>-0.072564</td>\n      <td>0.545064</td>\n      <td>0.025525</td>\n      <td>-295.635437</td>\n      <td>-289.678925</td>\n      <td>-0.515474</td>\n      <td>-0.350085</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.669300</td>\n      <td>0.708836</td>\n      <td>-0.050920</td>\n      <td>-0.078825</td>\n      <td>0.557940</td>\n      <td>0.027905</td>\n      <td>-295.674255</td>\n      <td>-289.741516</td>\n      <td>-0.519646</td>\n      <td>-0.353376</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.731100</td>\n      <td>0.721525</td>\n      <td>-0.051471</td>\n      <td>-0.084126</td>\n      <td>0.557940</td>\n      <td>0.032656</td>\n      <td>-295.679749</td>\n      <td>-289.794556</td>\n      <td>-0.520671</td>\n      <td>-0.355120</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.733200</td>\n      <td>0.706701</td>\n      <td>-0.057187</td>\n      <td>-0.083487</td>\n      <td>0.551502</td>\n      <td>0.026300</td>\n      <td>-295.736877</td>\n      <td>-289.788147</td>\n      <td>-0.517878</td>\n      <td>-0.351457</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.722700</td>\n      <td>0.713051</td>\n      <td>-0.052606</td>\n      <td>-0.079143</td>\n      <td>0.560086</td>\n      <td>0.026537</td>\n      <td>-295.691040</td>\n      <td>-289.744690</td>\n      <td>-0.518799</td>\n      <td>-0.352549</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.707800</td>\n      <td>0.731702</td>\n      <td>-0.052017</td>\n      <td>-0.081873</td>\n      <td>0.580472</td>\n      <td>0.029857</td>\n      <td>-295.685181</td>\n      <td>-289.772003</td>\n      <td>-0.519083</td>\n      <td>-0.353646</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.735800</td>\n      <td>0.714385</td>\n      <td>-0.052457</td>\n      <td>-0.084719</td>\n      <td>0.570815</td>\n      <td>0.032262</td>\n      <td>-295.689575</td>\n      <td>-289.800476</td>\n      <td>-0.518202</td>\n      <td>-0.352025</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.694700</td>\n      <td>0.719077</td>\n      <td>-0.055575</td>\n      <td>-0.082679</td>\n      <td>0.559013</td>\n      <td>0.027103</td>\n      <td>-295.720795</td>\n      <td>-289.780029</td>\n      <td>-0.519556</td>\n      <td>-0.354238</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.740100</td>\n      <td>0.729095</td>\n      <td>-0.049042</td>\n      <td>-0.083677</td>\n      <td>0.587983</td>\n      <td>0.034635</td>\n      <td>-295.655457</td>\n      <td>-289.790039</td>\n      <td>-0.517773</td>\n      <td>-0.352357</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.724100</td>\n      <td>0.724798</td>\n      <td>-0.054125</td>\n      <td>-0.084962</td>\n      <td>0.563305</td>\n      <td>0.030837</td>\n      <td>-295.706268</td>\n      <td>-289.802887</td>\n      <td>-0.517374</td>\n      <td>-0.352357</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"!zip -r /kaggle/working/trained_dpo_js_kl.zip /kaggle/working/trained_dpo_js_kl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T20:38:11.071584Z","iopub.execute_input":"2025-03-16T20:38:11.071931Z","iopub.status.idle":"2025-03-16T20:40:08.679424Z","shell.execute_reply.started":"2025-03-16T20:38:11.071901Z","shell.execute_reply":"2025-03-16T20:40:08.678546Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/trained_dpo_js_kl/ (stored 0%)\n  adding: kaggle/working/trained_dpo_js_kl/merges.txt (deflated 55%)\n  adding: kaggle/working/trained_dpo_js_kl/tokenizer.json (deflated 82%)\n  adding: kaggle/working/trained_dpo_js_kl/generation_config.json (deflated 30%)\n  adding: kaggle/working/trained_dpo_js_kl/config.json (deflated 46%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/ (stored 0%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/rng_state.pth (deflated 25%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/merges.txt (deflated 55%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/trainer_state.json (deflated 78%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/tokenizer.json (deflated 82%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/generation_config.json (deflated 30%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/config.json (deflated 46%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/scheduler.pt (deflated 56%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/training_args.bin (deflated 52%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/tokenizer_config.json (deflated 85%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/model.safetensors (deflated 21%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/special_tokens_map.json (deflated 71%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/vocab.json (deflated 59%)\n  adding: kaggle/working/trained_dpo_js_kl/checkpoint-200/optimizer.pt (deflated 24%)\n  adding: kaggle/working/trained_dpo_js_kl/training_args.bin (deflated 52%)\n  adding: kaggle/working/trained_dpo_js_kl/tokenizer_config.json (deflated 85%)\n  adding: kaggle/working/trained_dpo_js_kl/model.safetensors (deflated 21%)\n  adding: kaggle/working/trained_dpo_js_kl/special_tokens_map.json (deflated 71%)\n  adding: kaggle/working/trained_dpo_js_kl/vocab.json (deflated 59%)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import os \nfrom IPython.display import FileLink\n\n\nos.chdir(r'/kaggle/working')\nFileLink(r'trained_dpo_js_kl.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T20:40:08.680703Z","iopub.execute_input":"2025-03-16T20:40:08.681055Z","iopub.status.idle":"2025-03-16T20:40:08.688230Z","shell.execute_reply.started":"2025-03-16T20:40:08.681027Z","shell.execute_reply":"2025-03-16T20:40:08.687510Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/trained_dpo_js_kl.zip","text/html":"<a href='trained_dpo_js_kl.zip' target='_blank'>trained_dpo_js_kl.zip</a><br>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result_dpo_01 = get_win_rate_kl(\"/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1\",\n                               config.model_name,\n                               pair_rm)\nresult_dpo_01\n# {'model_path': '/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1',\n#  'win_rate': 0.43,\n#  'kl': 0.002710602007052546}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T22:09:41.520854Z","iopub.execute_input":"2025-03-24T22:09:41.521213Z","iopub.status.idle":"2025-03-24T22:19:08.333518Z","shell.execute_reply.started":"2025-03-24T22:09:41.521159Z","shell.execute_reply":"2025-03-24T22:19:08.332771Z"}},"outputs":[{"name":"stdout","text":"WARNING 03-24 22:09:41 [config.py:2599] Casting torch.bfloat16 to torch.float16.\nINFO 03-24 22:09:41 [config.py:583] This model supports multiple tasks: {'generate', 'score', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\nINFO 03-24 22:09:41 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.1) with config: model='HuggingFaceTB/SmolLM-135M-Instruct', speculative_config=None, tokenizer='HuggingFaceTB/SmolLM-135M-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=HuggingFaceTB/SmolLM-135M-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \nINFO 03-24 22:09:45 [model_runner.py:1110] Starting to load model HuggingFaceTB/SmolLM-135M-Instruct...\nINFO 03-24 22:09:45 [weight_utils.py:257] Using model weights format ['*.safetensors']\nINFO 03-24 22:09:45 [weight_utils.py:307] No model.safetensors.index.json found in remote.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d20e1bc5fb5443191fb6a30c3a1de88"}},"metadata":{}},{"name":"stdout","text":"INFO 03-24 22:09:45 [loader.py:429] Loading weights took 0.26 seconds\nINFO 03-24 22:09:48 [model_runner.py:1146] Model loading took 0.2551 GB and 0.488409 seconds\nINFO 03-24 22:09:53 [worker.py:267] Memory profiling takes 2.65 seconds\nINFO 03-24 22:09:53 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.40) = 5.90GiB\nINFO 03-24 22:09:53 [worker.py:267] model weights take 0.26GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.45GiB; the rest of the memory reserved for KV Cache is 5.19GiB.\nINFO 03-24 22:09:55 [executor_base.py:111] # cuda blocks: 15128, # CPU blocks: 11650\nINFO 03-24 22:09:55 [executor_base.py:116] Maximum concurrency for 2048 tokens per request: 118.19x\nINFO 03-24 22:09:56 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","output_type":"stream"},{"name":"stderr","text":"Capturing CUDA graph shapes: 100%|██████████| 35/35 [02:57<00:00,  5.07s/it]","output_type":"stream"},{"name":"stdout","text":"INFO 03-24 22:12:53 [model_runner.py:1570] Graph capturing finished in 177 secs, took 0.04 GiB\nINFO 03-24 22:12:53 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 185.25 seconds\nWARNING 03-24 22:12:53 [config.py:2599] Casting torch.bfloat16 to torch.float16.\nINFO 03-24 22:12:53 [config.py:583] This model supports multiple tasks: {'generate', 'score', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\nINFO 03-24 22:12:53 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.1) with config: model='/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1', speculative_config=None, tokenizer='/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"INFO 03-24 22:12:56 [model_runner.py:1110] Starting to load model /kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67de5d56ec6842dc9121dbbeb3b252df"}},"metadata":{}},{"name":"stdout","text":"INFO 03-24 22:12:56 [loader.py:429] Loading weights took 0.25 seconds\nINFO 03-24 22:12:59 [model_runner.py:1146] Model loading took 0.2541 GB and 0.302271 seconds\nINFO 03-24 22:13:04 [worker.py:267] Memory profiling takes 2.74 seconds\nINFO 03-24 22:13:04 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.40) = 5.90GiB\nINFO 03-24 22:13:04 [worker.py:267] model weights take 0.25GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.45GiB; the rest of the memory reserved for KV Cache is 5.19GiB.\nINFO 03-24 22:13:07 [executor_base.py:111] # cuda blocks: 15131, # CPU blocks: 11650\nINFO 03-24 22:13:07 [executor_base.py:116] Maximum concurrency for 2048 tokens per request: 118.21x\nINFO 03-24 22:13:07 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","output_type":"stream"},{"name":"stderr","text":"Capturing CUDA graph shapes: 100%|██████████| 35/35 [03:03<00:00,  5.25s/it]","output_type":"stream"},{"name":"stdout","text":"INFO 03-24 22:16:11 [model_runner.py:1570] Graph capturing finished in 184 secs, took 0.04 GiB\nINFO 03-24 22:16:11 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 191.97 seconds\n","output_type":"stream"},{"name":"stderr","text":"\nProcessed prompts: 100%|██████████| 100/100 [00:34<00:00,  2.91it/s, est. speed input: 1265.33 toks/s, output: 2010.51 toks/s]\nProcessed prompts: 100%|██████████| 100/100 [00:31<00:00,  3.21it/s, est. speed input: 1396.40 toks/s, output: 2220.51 toks/s]\nRanking candidates: 100%|██████████| 50/50 [01:50<00:00,  2.21s/it]\n","output_type":"stream"},{"name":"stdout","text":"len logprobs: 560\nlen logprobs: 514\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'model_path': '/kaggle/input/trained-dpo-beta-01-2v/kaggle/working/trained_dpo_beta_0.1',\n 'win_rate': 0.43,\n 'kl': 0.002710602007052546}"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"result_dpo_005 = get_win_rate_kl(\"/kaggle/input/trained-dpo-beta-005/kaggle/working/trained_dpo_beta_0.05\",\n                               config.model_name,\n                               pair_rm)\nresult_dpo_005\n# {'model_path': '/kaggle/input/trained-dpo-beta-005/kaggle/working/trained_dpo_beta_0.05',\n#  'win_rate': 0.56,\n#  'kl': 0.04896892805607254}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:01:57.098414Z","iopub.execute_input":"2025-03-25T20:01:57.098801Z","iopub.status.idle":"2025-03-25T20:01:57.103681Z","shell.execute_reply.started":"2025-03-25T20:01:57.098774Z","shell.execute_reply":"2025-03-25T20:01:57.103017Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.04896892805607254"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"result_dpo_forward = get_win_rate_kl(\"/kaggle/input/trained-dpo-forward-kl/kaggle/working/trained_dpo_forward_kl\",\n                               config.model_name,\n                               pair_rm)\nresult_dpo_forward\n\n# {'model_path': '/kaggle/input/trained-dpo-forward-kl/kaggle/working/trained_dpo_forward_kl',\n#  'win_rate': 0.44,\n#  'kl': 0.030309515614999075}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:08:00.969370Z","iopub.execute_input":"2025-03-25T20:08:00.969691Z","iopub.status.idle":"2025-03-25T20:08:00.975084Z","shell.execute_reply.started":"2025-03-25T20:08:00.969667Z","shell.execute_reply":"2025-03-25T20:08:00.974122Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0.030309515614999075"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"result_dpo_alpha = get_win_rate_kl(\"/kaggle/input/trained-dpo-alpha-kl/kaggle/working/trained_dpo_alpha_kl\",\n                               config.model_name,\n                               pair_rm)\nresult_dpo_alpha","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:11:29.768157Z","iopub.execute_input":"2025-03-25T20:11:29.768486Z","iopub.status.idle":"2025-03-25T20:12:17.923186Z","shell.execute_reply.started":"2025-03-25T20:11:29.768464Z","shell.execute_reply":"2025-03-25T20:12:17.921835Z"}},"outputs":[{"name":"stdout","text":"WARNING 03-25 20:11:29 [config.py:2614] Casting torch.bfloat16 to torch.float16.\nINFO 03-25 20:11:29 [config.py:585] This model supports multiple tasks: {'generate', 'embed', 'score', 'reward', 'classify'}. Defaulting to 'generate'.\nINFO 03-25 20:11:29 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.2) with config: model='HuggingFaceTB/SmolLM-135M-Instruct', speculative_config=None, tokenizer='HuggingFaceTB/SmolLM-135M-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=HuggingFaceTB/SmolLM-135M-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \nINFO 03-25 20:11:30 [model_runner.py:1110] Starting to load model HuggingFaceTB/SmolLM-135M-Instruct...\nINFO 03-25 20:11:30 [weight_utils.py:265] Using model weights format ['*.safetensors']\nINFO 03-25 20:11:30 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22fc410b502c4e87adadc1be7d8f44db"}},"metadata":{}},{"name":"stdout","text":"INFO 03-25 20:11:31 [loader.py:447] Loading weights took 0.25 seconds\nINFO 03-25 20:11:31 [model_runner.py:1146] Model loading took 0.2541 GB and 0.376847 seconds\nINFO 03-25 20:11:32 [worker.py:267] Memory profiling takes 0.65 seconds\nINFO 03-25 20:11:32 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.40) = 5.90GiB\nINFO 03-25 20:11:32 [worker.py:267] model weights take 0.25GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.45GiB; the rest of the memory reserved for KV Cache is 5.19GiB.\nINFO 03-25 20:11:33 [executor_base.py:111] # cuda blocks: 15130, # CPU blocks: 11650\nINFO 03-25 20:11:33 [executor_base.py:116] Maximum concurrency for 2048 tokens per request: 118.20x\nINFO 03-25 20:11:33 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","output_type":"stream"},{"name":"stderr","text":"Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:37<00:00,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"INFO 03-25 20:12:11 [model_runner.py:1570] Graph capturing finished in 38 secs, took 0.04 GiB\nINFO 03-25 20:12:11 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 39.83 seconds\nWARNING 03-25 20:12:11 [config.py:2614] Casting torch.bfloat16 to torch.float16.\nINFO 03-25 20:12:11 [config.py:585] This model supports multiple tasks: {'generate', 'embed', 'score', 'reward', 'classify'}. Defaulting to 'generate'.\nINFO 03-25 20:12:11 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.2) with config: model='/kaggle/input/trained-dpo-alpha-kl/kaggle/working/trained_dpo_alpha_kl', speculative_config=None, tokenizer='/kaggle/input/trained-dpo-alpha-kl/kaggle/working/trained_dpo_alpha_kl', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/kaggle/input/trained-dpo-alpha-kl/kaggle/working/trained_dpo_alpha_kl, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"INFO 03-25 20:12:12 [model_runner.py:1110] Starting to load model /kaggle/input/trained-dpo-alpha-kl/kaggle/working/trained_dpo_alpha_kl...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4e6544b1c64bfaac9051b990380974"}},"metadata":{}},{"name":"stdout","text":"INFO 03-25 20:12:15 [loader.py:447] Loading weights took 2.79 seconds\nINFO 03-25 20:12:15 [model_runner.py:1146] Model loading took 0.2536 GB and 2.847477 seconds\nINFO 03-25 20:12:17 [worker.py:267] Memory profiling takes 0.71 seconds\nINFO 03-25 20:12:17 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.40) = 5.90GiB\nINFO 03-25 20:12:17 [worker.py:267] model weights take 0.25GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.45GiB; the rest of the memory reserved for KV Cache is 5.20GiB.\nINFO 03-25 20:12:17 [executor_base.py:111] # cuda blocks: 15132, # CPU blocks: 11650\nINFO 03-25 20:12:17 [executor_base.py:116] Maximum concurrency for 2048 tokens per request: 118.22x\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-379d00d76c9c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result_dpo_alpha = get_win_rate_kl(\"/kaggle/input/trained-dpo-alpha-kl/kaggle/working/trained_dpo_alpha_kl\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                                \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                pair_rm)\n\u001b[1;32m      4\u001b[0m \u001b[0mresult_dpo_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-42a14de23e35>\u001b[0m in \u001b[0;36mget_win_rate_kl\u001b[0;34m(model_path, sft_model, pair_rm)\u001b[0m\n\u001b[1;32m      4\u001b[0m                                  \u001b[0mlogprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcomparison_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_rlhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_sft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_outputs_rlhf_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_outputs_sft_logprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgive_text_answers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_rm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_logprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_logprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_outputs_rlhf_logprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msft_logprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_logprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_outputs_sft_logprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-f4d1927a5d10>\u001b[0m in \u001b[0;36mgive_text_answers\u001b[0;34m(prompts, pair_rm_model, model_sft, model_rlhf, sampling_params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgive_text_answers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_rm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_sft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_rlhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel_sft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_sft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_memory_utilization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel_rlhf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_rlhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_memory_utilization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moutputs_sft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_sft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                     )\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Create the Engine (autoselects V0 vs V1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         self.llm_engine = LLMEngine.from_engine_args(\n\u001b[0m\u001b[1;32m    244\u001b[0m             engine_args=engine_args, usage_context=UsageContext.LLM_CLASS)\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mengine_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV1LLMEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         return engine_cls.from_vllm_config(\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0mvllm_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0musage_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musage_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_vllm_config\u001b[0;34m(cls, vllm_config, usage_context, stat_loggers, disable_log_stats)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mdisable_log_stats\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     ) -> \"LLMEngine\":\n\u001b[0;32m--> 496\u001b[0;31m         return cls(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mvllm_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mexecutor_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_executor_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, mm_registry, use_cached_outputs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"pooling\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_kv_caches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# If usage stat is enabled, collect relevant info.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36m_initialize_kv_caches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cpu_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cpu_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_gpu_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cpu_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         logger.info((\"init engine (profile, create kv cache, \"\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/executor_base.py\u001b[0m in \u001b[0;36minitialize_cache\u001b[0;34m(self, num_gpu_blocks, num_cpu_blocks)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cpu_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cpu_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         self.collective_rpc(\"initialize_cache\",\n\u001b[0m\u001b[1;32m    123\u001b[0m                             args=(num_gpu_blocks, num_cpu_blocks))\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/uniproc_executor.py\u001b[0m in \u001b[0;36mcollective_rpc\u001b[0;34m(self, method, timeout, args, kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/utils.py\u001b[0m in \u001b[0;36mrun_method\u001b[0;34m(obj, method, args, kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/worker.py\u001b[0m in \u001b[0;36minitialize_cache\u001b[0;34m(self, num_gpu_blocks, num_cpu_blocks)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_cache_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warm_up_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/worker.py\u001b[0m in \u001b[0;36m_init_cache_engine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_cache_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpu_blocks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         self.cache_engine = [\n\u001b[0m\u001b[1;32m    313\u001b[0m             CacheEngine(self.cache_config, self.model_config,\n\u001b[1;32m    314\u001b[0m                         self.parallel_config, self.device_config)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/worker.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpu_blocks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         self.cache_engine = [\n\u001b[0;32m--> 313\u001b[0;31m             CacheEngine(self.cache_config, self.model_config,\n\u001b[0m\u001b[1;32m    314\u001b[0m                         self.parallel_config, self.device_config)\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_parallel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/cache_engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cache_config, model_config, parallel_config, device_config)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Initialize the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         self.gpu_cache = self._allocate_kv_cache(\n\u001b[0m\u001b[1;32m     65\u001b[0m             self.num_gpu_blocks, self.device_config.device_type)\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allocate_kv_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cpu_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/cache_engine.py\u001b[0m in \u001b[0;36m_allocate_kv_cache\u001b[0;34m(self, num_blocks, device)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# block to be zeroed-out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# We zero-out everything for simplicity.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             layer_kv_cache = torch.zeros(kv_cache_shape,\n\u001b[0m\u001b[1;32m     84\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                          \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 132.12 MiB is free. Process 3363 has 14.58 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, with 48.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 132.12 MiB is free. Process 3363 has 14.58 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, with 48.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}